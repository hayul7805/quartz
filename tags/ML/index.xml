<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>ML on</title><link>https://hayul7805.github.io/quartz/tags/ML/</link><description>Recent content in ML on</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><atom:link href="https://hayul7805.github.io/quartz/tags/ML/index.xml" rel="self" type="application/rss+xml"/><item><title>Machine Learning</title><link>https://hayul7805.github.io/quartz/notes/Machine-Learning/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://hayul7805.github.io/quartz/notes/Machine-Learning/</guid><description>ML 대표 알고리즘 Logistic Regression Decision Tree Naïve Bayes Support Vector Machine K Nearest Neighbors Decision Tree 기반 Ensemble 모형 Random Forest Extra Trees Boosting Decision Tree 기반 Gradient Boosting 모형 Extreme Gradient Boosting Light Gradient Boosting Categorical Gradient Boosting Natural Gradient Boosting [!</description></item><item><title>Model tuning</title><link>https://hayul7805.github.io/quartz/notes/Model-tuning/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://hayul7805.github.io/quartz/notes/Model-tuning/</guid><description>그리드 탐색 알고리즘 내 효과적인 하이퍼파라미터 조합을 찾을 때까지, 탐색하고자 하는 하이퍼파라미터와 그에 해당하는 시도해볼 값들을 지정하여 하이퍼파라미터 튜닝을 진행하는 것 사이킷런의 GridSearchCV 클래스를 사용하여, 미리 설정한 하이퍼파라미터 조합에 대해 교차검증을 진행하고, 이를 통해 평가를 할 수 있다 RandomForestRegressor에 GridSearchCV 적용하기 3X4개의 Hyperparameter Tuning 2X3개의 Hyperparameter Tuning 5회 Cross Validation 진행 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 from sklearn.</description></item><item><title>XGB Modeling</title><link>https://hayul7805.github.io/quartz/notes/XGB-Modeling/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://hayul7805.github.io/quartz/notes/XGB-Modeling/</guid><description>1. XGB explained XGBoost의 특징 병렬처리 가능 GPU지원이 가능 추가적으로 정규화 기능, Tree pruning 기능, Early Stopping, 내장된 교차검증과 결측치 처리 등 XGBoost의 대표적인 파라미터 다룰 수 있는 파라미터가 많기 때문에 Customizing이 용이하다.</description></item><item><title>비지도학습 (Un-supervised Learning)</title><link>https://hayul7805.github.io/quartz/notes/%EB%B9%84%EC%A7%80%EB%8F%84%ED%95%99%EC%8A%B5-Un-supervised-Learning/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://hayul7805.github.io/quartz/notes/%EB%B9%84%EC%A7%80%EB%8F%84%ED%95%99%EC%8A%B5-Un-supervised-Learning/</guid><description>비지도학습 예시 군집 ( Clustering ) K-평균 ( K-Means ) DBSCAN 계층 군집 분석 ( Hierarchical Cluster Analysis : HCA ) 이상치/특이치탐지( Anomaly / Novelty Detection ) One-class SCM Isolation Forest 시각화 ( Visualization ) &amp;amp; 차원축소 ( Dimension Reduction ) 주성분 분석 ( Principal Component Analysis : PCA ) 커널 PCA ( Kernel PCA ) 지역적 선형 임베딩 ( Locally Linear Embedding : LLE ) T-SNE ( t-distributed stochastic neighbor embedding ) 연관규칙학습 ( Association Rule Learning )</description></item><item><title>지도학습 (Supervised Learning)</title><link>https://hayul7805.github.io/quartz/notes/%EC%A7%80%EB%8F%84%ED%95%99%EC%8A%B5-Supervised-Learning/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://hayul7805.github.io/quartz/notes/%EC%A7%80%EB%8F%84%ED%95%99%EC%8A%B5-Supervised-Learning/</guid><description>지도학습 대표 알고리즘 K-Nearest Neighbors (KNN) Linear Regression Logistic Regression Support Vector Machines (SVM) Decision Tree / Random Forest Gradient Boosting Algorithms ( XGB, LGB, CatGB, NGB 등) Neural Networks</description></item></channel></rss>