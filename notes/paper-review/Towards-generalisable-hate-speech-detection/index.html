<!doctype html><html lang=en><head><meta charset=utf-8><meta name=description content="[!info] Reference
Yin, W., & Zubiaga, A. (2021). Towards generalisable hate speech detection: a review on obstacles and solutions.Â PeerJ Computer Science,Â 7, e598."><meta property="og:title" content="Towards generalisable hate speech detection"><meta property="og:description" content="[!info] Reference
Yin, W., & Zubiaga, A. (2021). Towards generalisable hate speech detection: a review on obstacles and solutions.Â PeerJ Computer Science,Â 7, e598."><meta property="og:type" content="website"><meta property="og:image" content="https://hayul7805.github.io/quartz/icon.png"><meta property="og:url" content="https://hayul7805.github.io/quartz/notes/paper-review/Towards-generalisable-hate-speech-detection/"><meta property="og:width" content="200"><meta property="og:height" content="200"><meta name=twitter:card content="summary"><meta name=twitter:title content="Towards generalisable hate speech detection"><meta name=twitter:description content="[!info] Reference
Yin, W., & Zubiaga, A. (2021). Towards generalisable hate speech detection: a review on obstacles and solutions.Â PeerJ Computer Science,Â 7, e598."><meta name=twitter:image content="https://hayul7805.github.io/quartz/icon.png"><title>Towards generalisable hate speech detection</title><meta name=viewport content="width=device-width,initial-scale=1"><link rel="shortcut icon" type=image/png href=https://hayul7805.github.io/quartz//icon.png><link href=https://hayul7805.github.io/quartz/styles.7a7b335758325e783e6813b791081e23.min.css rel=stylesheet><link href=https://hayul7805.github.io/quartz/styles/_light_syntax.86a48a52faebeaaf42158b72922b1c90.min.css rel=stylesheet id=theme-link><script src=https://hayul7805.github.io/quartz/js/darkmode.f77f63bb01d142b61d2c12fbb4418858.min.js></script>
<script src=https://hayul7805.github.io/quartz/js/util.a0ccf91e1937fe761a74da4946452710.min.js></script>
<link rel=preload href=https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.css as=style onload='this.onload=null,this.rel="stylesheet"' integrity=sha384-R4558gYOUz8mP9YWpZJjofhk+zx0AS11p36HnD2ZKj/6JR5z27gSSULCNHIRReVs crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.js integrity=sha384-z1fJDqw8ZApjGO3/unPWUPsIymfsJmyrDVWC8Tv/a1HeOtGmkwNd/7xUS0Xcnvsx crossorigin=anonymous></script>
<script defer src=https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/contrib/auto-render.min.js integrity=sha384-+XBljXPPiv+OzfbB3cVmLHf4hdUFHlWNZN5spNQ7rmHTXpd7WvJum6fIACpNNfIR crossorigin=anonymous></script>
<script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.2/dist/contrib/copy-tex.min.js integrity=sha384-ww/583aHhxWkz5DEVn6OKtNiIaLi2iBRNZXfJRiY1Ai7tnJ9UXpEsyvOITVpTl4A crossorigin=anonymous></script>
<script src=https://cdn.jsdelivr.net/npm/@floating-ui/core@1.2.1></script>
<script src=https://cdn.jsdelivr.net/npm/@floating-ui/dom@1.2.1></script>
<script async src=https://hayul7805.github.io/quartz/js/popover.aa9bc99c7c38d3ae9538f218f1416adb.min.js></script>
<script defer src=https://hayul7805.github.io/quartz/js/code-title.ce4a43f09239a9efb48fee342e8ef2df.min.js></script>
<script defer src=https://hayul7805.github.io/quartz/js/clipboard.2913da76d3cb21c5deaa4bae7da38c9f.min.js></script>
<script defer src=https://hayul7805.github.io/quartz/js/callouts.7723cac461d613d118ee8bb8216b9838.min.js></script>
<script>const SEARCH_ENABLED=!1,LATEX_ENABLED=!0,PRODUCTION=!0,BASE_URL="https://hayul7805.github.io/quartz/",fetchData=Promise.all([fetch("https://hayul7805.github.io/quartz/indices/linkIndex.2745fa29d7b184f2bbb93b6e140bafd9.min.json").then(e=>e.json()).then(e=>({index:e.index,links:e.links})),fetch("https://hayul7805.github.io/quartz/indices/contentIndex.33b7d74fd2f60b1ee1fbda8be72b4033.min.json").then(e=>e.json())]).then(([{index:e,links:t},n])=>({index:e,links:t,content:n})),render=()=>{const e=new URL(BASE_URL),t=e.pathname,n=window.location.pathname,s=t==n;addCopyButtons(),addTitleToCodeBlocks(),addCollapsibleCallouts(),initPopover("https://hayul7805.github.io/quartz",!0);const o=document.getElementById("footer");if(o){const e=document.getElementById("graph-container");if(!e)return requestAnimationFrame(render);e.textContent="";const t=s&&!0;drawGraph("https://hayul7805.github.io/quartz",t,[{"/moc":"#4388cc"}],t?{centerForce:1,depth:-1,enableDrag:!0,enableLegend:!1,enableZoom:!0,fontSize:.5,linkDistance:1,opacityScale:3,repelForce:1,scale:1.4}:{centerForce:1,depth:1,enableDrag:!0,enableLegend:!1,enableZoom:!0,fontSize:.6,linkDistance:1,opacityScale:3,repelForce:2,scale:1.2})}var i=document.getElementsByClassName("mermaid");i.length>0&&import("https://unpkg.com/mermaid@9/dist/mermaid.esm.min.mjs").then(e=>{e.default.init()});function a(n){const e=n.target,t=e.className.split(" "),s=t.includes("broken"),o=t.includes("internal-link");plausible("Link Click",{props:{href:e.href,broken:s,internal:o,graph:!1}})}const r=document.querySelectorAll("a");for(link of r)link.className.includes("root-title")&&link.addEventListener("click",a,{once:!0})},init=(e=document)=>{addCopyButtons(),addTitleToCodeBlocks(),renderMathInElement(e.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1}],macros:{'â€™':"'"},throwOnError:!1})}</script><script type=module>
    import { attachSPARouting } from "https:\/\/hayul7805.github.io\/quartz\/js\/router.d6fe6bd821db9ea97f9aeefae814d8e7.min.js"
    attachSPARouting(init, render)
  </script><script defer data-domain=hayul7805.github.io/quartz src=https://plausible.io/js/script.js></script>
<script>window.plausible=window.plausible||function(){(window.plausible.q=window.plausible.q||[]).push(arguments)}</script></head><body><div id=search-container><div id=search-space><input autocomplete=off id=search-bar name=search type=text aria-label=Search placeholder="Search for something..."><div id=results-container></div></div></div><script src=https://cdn.jsdelivr.net/npm/flexsearch@0.7.21/dist/flexsearch.bundle.js integrity="sha256-i3A0NZGkhsKjVMzFxv3ksk0DZh3aXqu0l49Bbh0MdjE=" crossorigin=anonymous defer></script>
<script defer src=https://hayul7805.github.io/quartz/js/full-text-search.e6e2e0c213187ca0c703d6e2c7a77fcd.min.js></script><div class=singlePage><header><h1 id=page-title><a class=root-title href=https://hayul7805.github.io/quartz/>ğŸª´ Hayul's digital garden</a></h1><div class=spacer></div><div id=search-icon><p>Search</p><svg tabindex="0" aria-labelledby="title desc" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 19.9 19.7"><title id="title">Search Icon</title><desc id="desc">Icon to open search</desc><g class="search-path" fill="none"><path stroke-linecap="square" d="M18.5 18.3l-5.4-5.4"/><circle cx="8" cy="8" r="7"/></g></svg></div><div class=darkmode><input class=toggle id=darkmode-toggle type=checkbox tabindex=-1>
<label id=toggle-label-light for=darkmode-toggle tabindex=-1><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" id="dayIcon" viewBox="0 0 35 35" style="enable-background:new 0 0 35 35"><title>Light Mode</title><path d="M6 17.5C6 16.672 5.328 16 4.5 16h-3C.672 16 0 16.672.0 17.5S.672 19 1.5 19h3C5.328 19 6 18.328 6 17.5zM7.5 26c-.414.0-.789.168-1.061.439l-2 2C4.168 28.711 4 29.086 4 29.5 4 30.328 4.671 31 5.5 31c.414.0.789-.168 1.06-.44l2-2C8.832 28.289 9 27.914 9 27.5 9 26.672 8.329 26 7.5 26zm10-20C18.329 6 19 5.328 19 4.5v-3C19 .672 18.329.0 17.5.0S16 .672 16 1.5v3C16 5.328 16.671 6 17.5 6zm10 3c.414.0.789-.168 1.06-.439l2-2C30.832 6.289 31 5.914 31 5.5 31 4.672 30.329 4 29.5 4c-.414.0-.789.168-1.061.44l-2 2C26.168 6.711 26 7.086 26 7.5 26 8.328 26.671 9 27.5 9zM6.439 8.561C6.711 8.832 7.086 9 7.5 9 8.328 9 9 8.328 9 7.5c0-.414-.168-.789-.439-1.061l-2-2C6.289 4.168 5.914 4 5.5 4 4.672 4 4 4.672 4 5.5c0 .414.168.789.439 1.06l2 2.001zM33.5 16h-3c-.828.0-1.5.672-1.5 1.5s.672 1.5 1.5 1.5h3c.828.0 1.5-.672 1.5-1.5S34.328 16 33.5 16zM28.561 26.439C28.289 26.168 27.914 26 27.5 26c-.828.0-1.5.672-1.5 1.5.0.414.168.789.439 1.06l2 2C28.711 30.832 29.086 31 29.5 31c.828.0 1.5-.672 1.5-1.5.0-.414-.168-.789-.439-1.061l-2-2zM17.5 29c-.829.0-1.5.672-1.5 1.5v3c0 .828.671 1.5 1.5 1.5s1.5-.672 1.5-1.5v-3C19 29.672 18.329 29 17.5 29zm0-22C11.71 7 7 11.71 7 17.5S11.71 28 17.5 28 28 23.29 28 17.5 23.29 7 17.5 7zm0 18c-4.136.0-7.5-3.364-7.5-7.5s3.364-7.5 7.5-7.5 7.5 3.364 7.5 7.5S21.636 25 17.5 25z"/></svg></label><label id=toggle-label-dark for=darkmode-toggle tabindex=-1><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" id="nightIcon" viewBox="0 0 100 100" style="enable-background='new 0 0 100 100'"><title>Dark Mode</title><path d="M96.76 66.458c-.853-.852-2.15-1.064-3.23-.534-6.063 2.991-12.858 4.571-19.655 4.571C62.022 70.495 50.88 65.88 42.5 57.5 29.043 44.043 25.658 23.536 34.076 6.47c.532-1.08.318-2.379-.534-3.23-.851-.852-2.15-1.064-3.23-.534-4.918 2.427-9.375 5.619-13.246 9.491-9.447 9.447-14.65 22.008-14.65 35.369.0 13.36 5.203 25.921 14.65 35.368s22.008 14.65 35.368 14.65c13.361.0 25.921-5.203 35.369-14.65 3.872-3.871 7.064-8.328 9.491-13.246C97.826 68.608 97.611 67.309 96.76 66.458z"/></svg></label></div></header><article><h1>Towards generalisable hate speech detection</h1><p class=meta>Last updated
Dec 12, 2022
<a href=https://github.com/hayul7805/notes/paper-review/Towards%20generalisable%20hate%20speech%20detection.md rel=noopener>Edit Source</a></p><ul class=tags><li><a href=https://hayul7805.github.io/quartz/tags/generalization/>Generalization</a></li><li><a href=https://hayul7805.github.io/quartz/tags/key-observation/>Key observation</a></li></ul><aside class=mainTOC><details><summary>Table of Contents</summary><nav id=TableOfContents><ol><li><a href=#generalisation>Generalisation</a></li><li><a href=#data>Data</a></li><li><a href=#obstacles-to-generalisable-hate-speech-detection>OBSTACLES TO GENERALISABLE HATE SPEECH DETECTION</a></li></ol></nav></details></aside><blockquote class=info-callout><p>Reference</p><p>Yin, W., & Zubiaga, A. (2021). Towards generalisable hate speech detection: a review on obstacles and solutions.Â <em>PeerJ Computer Science</em>,Â <em>7</em>, e598.</p></blockquote><hr><a href=#generalisation><h2 id=generalisation><span class=hanchor arialabel=Anchor># </span>Generalisation</h2></a><blockquote><p>Most if not all proposed hate speech detection models rely on supervised machine learning methods, where the ultimate purpose is for the model to learn the real relationship between features and predictions through training data, which generalises to previously unobserved inputs (Goodfellow, Bengio & Courville, 2016). The generalisation performance of a model measures how well it fulfils this purpose.</p></blockquote><ul><li>ì œì•ˆëœ í˜ì˜¤ ë°œì–¸ íƒì§€ ëª¨ë¸ì€ ëŒ€ë¶€ë¶„ supervised ê¸°ê³„ í•™ìŠµ ë°©ë²•ì— ì˜ì¡´í•˜ë©°, ê¶ê·¹ì ì¸ ëª©ì ì€ ëª¨ë¸ì´ ì´ì „ì— ê´€ì°°ë˜ì§€ ì•Šì€ ì…ë ¥ìœ¼ë¡œ ì¼ë°˜í™”í•˜ëŠ” í›ˆë ¨ ë°ì´í„°ë¥¼ í†µí•´ ê¸°ëŠ¥ê³¼ ì˜ˆì¸¡ ì‚¬ì´ì˜ ì‹¤ì œ ê´€ê³„ë¥¼ í•™ìŠµí•˜ëŠ” ê²ƒì´ë‹¤(Goodfellow, Bengio & Courville, 2016). ëª¨ë¸ì˜ ì¼ë°˜í™” ì„±ê³¼ëŠ” ì´ ëª©ì ì„ ì–¼ë§ˆë‚˜ ì˜ ë‹¬ì„±í•˜ëŠ”ì§€ ì¸¡ì •í•œë‹¤.</li></ul><blockquote><p>The ultimate purpose of studying automatic hate speech detection is to facilitate the alleviation of the harms brought by online hate speech. To fulfil this purpose, hate speech detection models need to be able to deal with the constant growth and evolution of hate speech, regardless of its form, target, and speaker.</p></blockquote><ul><li>ìë™ í˜ì˜¤í‘œí˜„ íƒì§€ë¥¼ ì—°êµ¬í•˜ëŠ” ê¶ê·¹ì ì¸ ëª©ì ì€ ì˜¨ë¼ì¸ í˜ì˜¤í‘œí˜„ì´ ê°€ì ¸ì˜¤ëŠ” í•´ì•…ì˜ ì™„í™”ë¥¼ ìš©ì´í•˜ê²Œ í•˜ëŠ” ê²ƒì´ë‹¤. ì´ëŸ¬í•œ ëª©ì ì„ ë‹¬ì„±í•˜ê¸° ìœ„í•´, í˜ì˜¤í‘œí˜„ íƒì§€ ëª¨ë¸ì€ í˜•íƒœ, ëŒ€ìƒ ë° í™”ìì— ê´€ê³„ì—†ì´ í˜ì˜¤ ë°œì–¸ì˜ ì§€ì†ì ì¸ ì„±ì¥ê³¼ ì§„í™”ë¥¼ ì²˜ë¦¬í•  ìˆ˜ ìˆì–´ì•¼ í•œë‹¤.</li></ul><p>#key-observation</p><blockquote><p>Recent research has raised concerns on the generalisability of existing models (Swamy, Jamatia & GambaÌˆck, 2019). Despite their impressive performance on their respective test sets, <strong>the performance significantly dropped when the models are applied to a different hate speech dataset.</strong> This means that the assumption that test data of existing datasets represent the distribution of future cases is not true, and that <strong>the generalisation performance of existing models have been severely overestimated</strong> (Arango, Prez & Poblete, 2020). This lack of generalisability undermines the practical value of these hate speech detection models.</p></blockquote><ul><li>ìµœê·¼ ì—°êµ¬ëŠ” ê¸°ì¡´ ëª¨ë¸ì˜ ì¼ë°˜í™” ê°€ëŠ¥ì„±ì— ëŒ€í•œ ìš°ë ¤ë¥¼ ì œê¸°í–ˆë‹¤(Swamy, Jamatia & Gambeck, 2019 :
<a href=/quartz/notes/paper-review/Studying-Generalisability-Across-Abusive-Language-Detection-Datasets/ rel=noopener class=internal-link data-src=/quartz/notes/paper-review/Studying-Generalisability-Across-Abusive-Language-Detection-Datasets/>Studying Generalisability Across Abusive Language Detection Datasets</a>). <strong>ê°ê°ì˜ í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ì—ì„œ ì¸ìƒì ì¸ ì„±ëŠ¥ì—ë„ ë¶ˆêµ¬í•˜ê³  ëª¨ë¸ì´ ë‹¤ë¥¸ í˜ì˜¤ ìŒì„± ë°ì´í„° ì„¸íŠ¸ì— ì ìš©ë  ë•Œ ì„±ëŠ¥ì´ í¬ê²Œ ë–¨ì–´ì¡Œë‹¤.</strong> ì´ëŠ” ê¸°ì¡´ ë°ì´í„° ì„¸íŠ¸ì˜ í…ŒìŠ¤íŠ¸ ë°ì´í„°ê°€ ë¯¸ë˜ì˜ ì‚¬ë¡€ ë¶„í¬ë¥¼ ë‚˜íƒ€ë‚¸ë‹¤ëŠ” ê°€ì •ì´ ì‚¬ì‹¤ì´ ì•„ë‹ˆë©°, <strong>ê¸°ì¡´ ëª¨ë¸ì˜ ì¼ë°˜í™” ì„±ëŠ¥ì´ ì‹¬ê°í•˜ê²Œ ê³¼ëŒ€ í‰ê°€ë˜ì—ˆë‹¤ëŠ” ê²ƒì„ ì˜ë¯¸í•œë‹¤</strong>(Arango, Pres & Poblete, 2020 :
<a href=/quartz/notes/paper-review/Hate-speech-detection-is-not-as-easy-as-you-may-think/ rel=noopener class=internal-link data-src=/quartz/notes/paper-review/Hate-speech-detection-is-not-as-easy-as-you-may-think/>Hate speech detection is not as easy as you may think</a>). ì´ëŸ¬í•œ ì¼ë°˜ì„±ì˜ ë¶€ì¡±ì€ ì´ëŸ¬í•œ í˜ì˜¤í‘œí˜„ íƒì§€ ëª¨ë¸ì˜ ì‹¤ì§ˆì ì¸ ê°€ì¹˜ë¥¼ í›¼ì†í•œë‹¤.</li></ul><blockquote class=note-callout><p>Note</p><p>ì´ ë¶€ë¶„ì´ ë‚´ê°€ í•˜ê³  ìˆëŠ” ì—°êµ¬ì˜ í•µì‹¬ì´ë‹¤! ëª¨ë¸ì˜ ì¼ë°˜í™” ì„±ëŠ¥ì´ ê³¼ëŒ€í‰ê°€ë˜ì–´ ìˆë‹¤ëŠ” ê²ƒ. í•œêµ­ì–´ ë°ì´í„°ì…‹ê³¼ ëª¨ë¸ë¡œë„ ë¹„ìŠ·í•œ ê²°ê³¼ê°€ ë‚˜ì˜¤ëŠ”ì§€ ë³´ëŠ” ê²ƒ.</p></blockquote><a href=#data><h2 id=data><span class=hanchor arialabel=Anchor># </span>Data</h2></a><blockquote><p>[ì˜ˆì‹œ 1]
For example, in Wiegand, Ruppenhofer & Kleinbauer (2019)â€™s study, FastText models (Joulin et al., 2017a) trained on three datasets (Kaggle, Founta, Razavi) achieved F1 scores above 70 when tested on one another, <strong>while models trained or tested on datasets outside this group achieved around 60 or less</strong>.</p></blockquote><ul><li>ëª¨ë¸ì´ í›ˆë ¨ëœ ê²ƒê³¼ ë‹¤ë¥¸ ë°ì´í„°ì…‹ì—ì„œëŠ” ëª¨ë¸ì˜ ì„±ëŠ¥ì´ ë–¨ì–´ì§„ë‹¤ëŠ” ê²°ê³¼ê°€ ìˆë‹¤.</li></ul><p>#key-observation</p><blockquote><p>Founta and OLID produced models that performed well on each other. The source of such differences are usually traced back to search terms (Swamy, Jamatia & GambÃ¤ck, 2019), topics covered (Nejadgholi & Kiritchenko, 2020; Pamungkas, Basile & Patti, 2020), label definitions (Pamungkas & Patti, 2019; Pamungkas, Basile & Patti, 2020; Fortuna, Soler-Company & Wanner, 2021), and data source platforms (GlavaÅ¡, Karan & VuliÄ‡, 2020; Karan & Å najder, 2018).</p></blockquote><ul><li>ì„œë¡œ í…ŒìŠ¤íŠ¸ ì„±ëŠ¥ì´ ì˜ ë‚˜ì˜¤ëŠ” ë°ì´í„°ì…‹ì€ ê·¸ ê·¼ì›ì„ ë”°ë¼ê°€ë³´ë©´ ì•Œ ìˆ˜ ìˆëŠ” ì‚¬ì‹¤ì´ ìˆë‹¤. ì˜ˆë¥¼ ë“¤ë©´,<code> Founta</code>ì™€ <code>OLID</code> ë°ì´í„°ì…‹ì€ ì„œë¡œ ë¹„ìŠ·í•œ ë°ì´í„°ë¥¼ ê³µìœ í•˜ê³  ìˆë‹¤.</li></ul><blockquote><p>Fortuna, Soler & Wanner (2020) used averaged word embeddings (Bojanowski et al., 2017; Mikolov et al., 2018) to compute the representations of classes from different datasets, and compared classes across datasets. <strong>One of their observations is that Davidsonâ€™s â€˜â€˜hate speechâ€™â€™ is very different from Waseemâ€™s â€˜â€˜hate speechâ€™â€™, â€˜â€˜racismâ€™â€™, â€˜â€˜sexismâ€™â€™, while being relatively close to HatEvalâ€™s â€˜â€˜hate speechâ€™â€™ and Kaggleâ€™s â€˜â€˜identity hateâ€™â€™.</strong> This echoes with experiments that showed poor generalisation of models from Waseem to HatEval (Arango, Prez & Poblete, 2020) and between Davidson and Waseem (Waseem, Thorne & Bingel, 2018; GroÌˆndahl et al., 2018).</p></blockquote><ul><li>í˜ì˜¤í‘œí˜„ ë°ì´í„°ì…‹ì—ì„œ ìì£¼ ë‚˜ì˜¤ëŠ” ë‹¨ì–´ë“¤ì¸ &lsquo;hate speech&rsquo;, &lsquo;racism&rsquo;, &lsquo;sexism&rsquo; ë“±ë„ ì›Œë“œ ì„ë² ë”©ì„ í†µí•´ ì‚´í´ë³´ë‹ˆ ë°ì´í„°ì…‹ë§ˆë‹¤ ê·¸ ì˜ë¯¸ê°€ ë‹¤ë¥´ë‹¤ëŠ” ê´€ì°°ì´ ë‚˜ì™”ë‹¤. ì´ëŠ” ë‹¹ì—°íˆ ëª¨ë¸ ì„±ëŠ¥ì˜ ì¼ë°˜í™”ì—ë„ ì•…ì˜í–¥ì„ ë¼ì³¤ê³  ë§ì´ë‹¤.</li></ul><blockquote><p>In terms of what properties of a dataset lead to more generalisable models, there are frequently mentioned factors (&mldr;)</p></blockquote><blockquote><p>Biases in the samples are also frequently mentioned. <strong>Wiegand, Ruppenhofer & Kleinbauer (2019) hold that less biased sampling approaches produce more generalisable models.</strong> This was later reproduced by Razo & KÃ¼bler (2020) and also helps explain their results with the two datasets that have the least positive cases. Similarly, Pamungkas & Patti (2019) mentioned that a wider coverage of phenomena lead to more generalisable models.</p></blockquote><ul><li><code>Wiegand, Ruppenhofer & Kleinbauer (2019)</code> ì—°êµ¬ì—ì„œ ì–¸ê¸‰í•œ ë°”ì™€ ê°™ì´, ì¡°ê¸ˆì´ë¼ë„ ë” ì¼ë°˜í™”ê°€ ì˜ ë˜ëŠ” ëª¨ë¸ì„ ë§Œë“œë ¤ë©´ samplingì„ ëœ ì¹˜ìš°ì¹˜ê²Œ í•´ì£¼ì–´ì•¼ í•œë‹¤. í›ˆë ¨ì‹œ <code>sampler</code>ë¥¼ ì˜ ë§Œë“¤ì–´ì•¼ê² ë‹¤.</li></ul><blockquote><p>Another way of looking at generalisation and similarity is by comparing differences between individual classes across datasets (Nejadgholi & Kiritchenko, 2020; Fortuna, Soler & Wanner, 2020; Fortuna, Soler-Company & Wanner, 2021), as opposed to comparing datasets as a whole.</p></blockquote><ul><li>ì´ ë…¼ë¬¸ì—ì„œë„ class ê°œë³„ë¡œ ë¹„êµí•˜ë¼ê³  ì£¼ì¥í•˜ëŠ”êµ¬ë‚˜.
<a href=/quartz/notes/paper-review/On-Cross-Dataset-Generalization-in-Automatic-Detection-of-Online-Abuse/ rel=noopener class=internal-link data-src=/quartz/notes/paper-review/On-Cross-Dataset-Generalization-in-Automatic-Detection-of-Online-Abuse/>On Cross-Dataset Generalization in Automatic Detection of Online Abuse</a> ì—ì„œ ì£¼ì¥í•˜ëŠ” ê²ƒê³¼ ë§ë¬¼ë¦°ë‹¤.</li></ul><a href=#obstacles-to-generalisable-hate-speech-detection><h2 id=obstacles-to-generalisable-hate-speech-detection><span class=hanchor arialabel=Anchor># </span>OBSTACLES TO GENERALISABLE HATE SPEECH DETECTION</h2></a><blockquote><p>Hate speech detection, which is largely focused on social media, shares similar challenges to other social media tasks and has its specific ones, <strong>when it comes to the grammar and vocabulary used.</strong> Such user language style introduces challenges to generalisability at the data source, mainly by making it difficult to utilise common NLP pre-training approaches.</p></blockquote><ul><li>í˜ì˜¤í‘œí˜„ íƒì§€ëŠ” ë¬¸ë²•ì´ë‚˜ ì–´íœ˜ ê´€ë ¨í•´ì„œ ì–´ë ¤ì›€ì´ ë§ë‹¤ëŠ” íŠ¹ì§•ì´ ìˆë‹¤.</li></ul><blockquote><p>On social media, syntax use is generally more casual, such as the omission of punctuation (Blodgett & Oâ€™Connor, 2017). Alternative spelling and expressions are also used in dialects (Blodgett & Oâ€™Connor, 2017), to save space, and to provide emotional emphasis (Baziotis, Pelekis & Doulkeridis, 2017). Sanguinetti et al. (2020) provided extensive guidelines for studying such phenomena syntactically.</p></blockquote><ul><li>ê·¸ë˜ì„œ í˜ì˜¤í‘œí˜„ íƒì§€ ì—°êµ¬ë¥¼ í•  ë•ŒëŠ” KcELECTRAê°€ ê·¸ë‚˜ë§ˆ ê´œì°®ê² êµ¬ë‚˜. ì´ëŸ¬í•œ ì¼€ì´ìŠ¤ê°€ ë§ì€ ë°ì´í„°ë¡œ ì‚¬ì „í•™ìŠµëœ ëª¨ë¸ì´ë‹ˆê¹Œ. ì‹¤ì œë¡œ ì„±ëŠ¥ë„ ê°€ì¥ ê´œì°®ê³ .</li></ul><blockquote><p>Qian et al. (2018) found that rare words and implicit expressions are the two main causes of false negatives; Van Aken et al. (2018) compared several models that used pre-trained word embeddings, and found that rare and unknown words were present in 30% of the false negatives of Wikipedia data and 43% of Twitter data.</p></blockquote><ul><li>ë˜í•œ rare words, implicit expressionsëŠ” false negativesë¥¼ ì¦ê°€ì‹œí‚¨ë‹¤. ì´ëŠ” ë”°ë¼ì„œ í•˜ë‚˜ì˜ ë„ë©”ì¸ì—ì„œë§Œ ìˆ˜ì§‘í•œ ë°ì´í„°ì…‹ì´ ê°€ì§€ëŠ” í•œê³„ì¼ ìˆ˜ ë°–ì— ì—†ê² ë‹¤. ì´ë¥¼ ê·¹ë³µí•˜ë ¤ë©´ ì—¬ëŸ¬ ë„ë©”ì¸ì—ì„œ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•´ì•¼ê² ë„¤.</li></ul><blockquote><p>Indeed, BERT (Devlin et al., 2019) and its variants have demonstrated top performances at hate or abusive speech detection challenges recently (Liu, Li & Zou, 2019; Mishra & Mishra, 2019).</p></blockquote><ul><li>BERT ê³„ì—´ ëª¨ë¸ì€ í˜ì˜¤í‘œí˜„ íƒì§€ì—ì„œë„ ì—¬ì „íˆ top í¼í¬ë¨¼ìŠ¤ë¥¼ ë³´ì¸ë‹¤.</li></ul><blockquote><p>It is particularly challenging to acquire labelled data for hate speech detection as knowledge or relevant training is required of the annotators. As a high-level and abstract concept, the judgement of â€˜â€˜hate speechâ€™â€™ is subjective, needing extra care when processing annotations. Hence, datasets are usually not big in size.</p></blockquote><ul><li>í˜ì˜¤í‘œí˜„ ë°ì´í„°ì…‹ì€ &lsquo;í˜ì˜¤í‘œí˜„&rsquo;ì„ ì •ì˜í•˜ëŠ” ê²ƒ ìì²´ê°€ ì£¼ê´€ì ì´ê¸° ë•Œë¬¸ì—, ì£¼ì„ ì²˜ë¦¬ì— ì¶”ê°€ì ì¸ í˜ì´ ë“¤ê³  ë”°ë¼ì„œ í° ì‚¬ì´ì¦ˆë¡œ ë§Œë“¤ì–´ì§€ê¸° ì–´ë µë‹¤.</li></ul><blockquote><p>Moreover, <strong>different studies are based on varying definitions of â€˜â€˜hate speechâ€™â€™, as seen in different annotation guidelines</strong> (Table 5). Despite all covering the same two main aspects (directly attack or promote hate towards), datasets vary by their wording, what they consider a target (any group, minority groups, specific minority groups), and their clarifications on edge cases.
Davidson and HatEval both distinguished â€˜â€˜hate speechâ€™â€™ from â€˜â€˜offensive languageâ€™â€™, while â€˜â€˜uses a sexist or racist slurâ€™â€™ is in Waseemâ€™s guidelines to mark a case positive of hate, <strong>blurring the boundary of offensive and hateful.</strong>
Additionally, as both HatEval and Waseem specified the types of hate (towards women and immigrants; racism and sexism), hate speech that fell outside of these specific types were not included in the positive classes, while Founta and Davidson included any type of hate speech.</p></blockquote><ul><li>ë˜í•œ, ë‹¤ë¥¸ ì£¼ì„ ì§€ì¹¨(í‘œ 5)ì—ì„œ ë³¼ ìˆ˜ ìˆë“¯ì´, ë‹¤ì–‘í•œ ì—°êµ¬ëŠ” &ldquo;í˜ì˜¤ ë°œì–¸"ì˜ ë‹¤ì–‘í•œ ì •ì˜ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•œë‹¤. ëª¨ë“  ê²ƒì´ ë™ì¼í•œ ë‘ ê°€ì§€ ì£¼ìš” ì¸¡ë©´ì„ í¬í•¨í•¨ì—ë„ ë¶ˆêµ¬í•˜ê³  ë°ì´í„° ì„¸íŠ¸ëŠ” í‘œí˜„, ëŒ€ìƒìœ¼ë¡œ ê°„ì£¼í•˜ëŠ” ê²ƒ(ëª¨ë“  ê·¸ë£¹, ì†Œìˆ˜ ê·¸ë£¹, íŠ¹ì • ì†Œìˆ˜ ê·¸ë£¹) ë° ì—£ì§€ ì‚¬ë¡€ì— ëŒ€í•œ ëª…í™•í™”ì— ë”°ë¼ ë‹¤ë¥´ë‹¤.</li><li>Davidsonê³¼ HatEvalì€ ëª¨ë‘ &ldquo;hate speech"ì™€ &ldquo;offensive language"ë¥¼ êµ¬ë¶„í–ˆìœ¼ë©°, &ldquo;ì„±ì°¨ë³„ì  ë˜ëŠ” ì¸ì¢…ì°¨ë³„ì  ë¹„ë°© ì‚¬ìš©"ì€ Waseemì˜ ê°€ì´ë“œë¼ì¸ì— hateë¡œ í‘œì‹œí•˜ì—¬ offensiveì™€ hateì˜ ê²½ê³„ë¥¼ ëª¨í˜¸í•˜ê²Œ í•œë‹¤.</li><li>ë˜í•œ, HatEvalê³¼ Waseemì´ í˜ì˜¤ì˜ ìœ í˜•(ì—¬ì„±ê³¼ ì´ë¯¼ìì— ëŒ€í•œ ê²ƒ; ì¸ì¢… ì°¨ë³„ê³¼ ì„±ì°¨ë³„)ì„ ëª…ì‹œí•¨ì— ë”°ë¼, ì´ëŸ¬í•œ íŠ¹ì • ìœ í˜•ì—ì„œ ë²—ì–´ë‚œ í˜ì˜¤ ë°œì–¸ì€ ê¸ì •ì ì¸ ë“±ê¸‰ì— í¬í•¨ë˜ì§€ ì•Šì•˜ê³ , ë°˜ë©´ Fontaì™€ Davidsonì€ ëª¨ë“  ìœ í˜•ì˜ í˜ì˜¤ ë°œì–¸ì„ í¬í•¨ì‹œì¼°ë‹¤.</li></ul></article><hr><div class=page-end id=footer><div class=backlinks-container><h3>Backlinks</h3><ul class=backlinks><li><a href=/quartz/notes/paper-review/ data-ctx="ğŸ“„ Towards generalisable hate speech detection" data-src=/notes/paper-review class=internal-link>ğŸ“‘ Paper Review</a></li></ul></div><div><script async src=https://cdn.jsdelivr.net/npm/d3@6.7.0/dist/d3.min.js integrity="sha256-+7jaYCp29O1JusNWHaYtgUn6EhuP0VaFuswhNV06MyI=" crossorigin=anonymous></script><h3>Interactive Graph</h3><div id=graph-container></div><style>:root{--g-node:var(--secondary);--g-node-active:var(--primary);--g-node-inactive:var(--visited);--g-link:var(--outlinegray);--g-link-active:#5a7282}</style><script src=https://hayul7805.github.io/quartz/js/graph.6579af7b10c818dbd2ca038702db0224.js></script></div></div><div id=contact_buttons><footer><p>Made by Hayul Park using <a href=https://github.com/jackyzha0/quartz>Quartz</a>, Â© 2023</p><ul><li><a href=https://hayul7805.github.io/quartz/>Home</a></li><li><a href=https://github.com/hayul7805>Github</a></li><li><a href=https://www.linkedin.com/in/hayulpark/>Linkedin</a></li></ul></footer></div></div></body></html>