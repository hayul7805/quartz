<!doctype html><html lang=en><head><meta charset=utf-8><meta name=description content="[!note] Note
ì´ë²ˆì— ì •ë¦¬í•˜ëŠ” ë…¼ë¬¸ì€ &ldquo;abusive content detect&rdquo; ê³¼ì œê°€ ì–´ë–»ê²Œ ë°œì „í–ˆê³ , ì§€ê¸ˆ ë§ˆì£¼í•˜ê³  ìˆëŠ” ì–´ë ¤ì›€ì€ ë¬´ì—‡ì¸ì§€ ì†Œê°œí•˜ëŠ” ë…¼ë¬¸ì´ë‹¤. í˜ì˜¤í‘œí˜„ íƒì§€ ê³¼ì œì™€ (ì™„ì „íˆëŠ” ì•„ë‹ˆì§€ë§Œ) ë¹„ìŠ·í•œ ê³¼ì œì´ê¸°ì— ë¹„ìŠ·í•œ ì–´ë ¤ì›€ë“¤ì„ ê³µìœ í•˜ê³  ìˆë‹¤."><meta property="og:title" content="Challenges and frontiers in abusive content detect"><meta property="og:description" content="[!note] Note
ì´ë²ˆì— ì •ë¦¬í•˜ëŠ” ë…¼ë¬¸ì€ &ldquo;abusive content detect&rdquo; ê³¼ì œê°€ ì–´ë–»ê²Œ ë°œì „í–ˆê³ , ì§€ê¸ˆ ë§ˆì£¼í•˜ê³  ìˆëŠ” ì–´ë ¤ì›€ì€ ë¬´ì—‡ì¸ì§€ ì†Œê°œí•˜ëŠ” ë…¼ë¬¸ì´ë‹¤. í˜ì˜¤í‘œí˜„ íƒì§€ ê³¼ì œì™€ (ì™„ì „íˆëŠ” ì•„ë‹ˆì§€ë§Œ) ë¹„ìŠ·í•œ ê³¼ì œì´ê¸°ì— ë¹„ìŠ·í•œ ì–´ë ¤ì›€ë“¤ì„ ê³µìœ í•˜ê³  ìˆë‹¤."><meta property="og:type" content="website"><meta property="og:image" content="https://hayul7805.github.io/quartz/icon.png"><meta property="og:url" content="https://hayul7805.github.io/quartz/notes/paper-review/Challenges-and-frontiers-in-abusive-content-detect/"><meta property="og:width" content="200"><meta property="og:height" content="200"><meta name=twitter:card content="summary"><meta name=twitter:title content="Challenges and frontiers in abusive content detect"><meta name=twitter:description content="[!note] Note
ì´ë²ˆì— ì •ë¦¬í•˜ëŠ” ë…¼ë¬¸ì€ &ldquo;abusive content detect&rdquo; ê³¼ì œê°€ ì–´ë–»ê²Œ ë°œì „í–ˆê³ , ì§€ê¸ˆ ë§ˆì£¼í•˜ê³  ìˆëŠ” ì–´ë ¤ì›€ì€ ë¬´ì—‡ì¸ì§€ ì†Œê°œí•˜ëŠ” ë…¼ë¬¸ì´ë‹¤. í˜ì˜¤í‘œí˜„ íƒì§€ ê³¼ì œì™€ (ì™„ì „íˆëŠ” ì•„ë‹ˆì§€ë§Œ) ë¹„ìŠ·í•œ ê³¼ì œì´ê¸°ì— ë¹„ìŠ·í•œ ì–´ë ¤ì›€ë“¤ì„ ê³µìœ í•˜ê³  ìˆë‹¤."><meta name=twitter:image content="https://hayul7805.github.io/quartz/icon.png"><title>Challenges and frontiers in abusive content detect</title><meta name=viewport content="width=device-width,initial-scale=1"><link rel="shortcut icon" type=image/png href=https://hayul7805.github.io/quartz//icon.png><link href=https://hayul7805.github.io/quartz/styles.f59ce067f652868ebdcf07fb2d1c3080.min.css rel=stylesheet><link href=https://hayul7805.github.io/quartz/styles/_light_syntax.86a48a52faebeaaf42158b72922b1c90.min.css rel=stylesheet id=theme-link><script src=https://hayul7805.github.io/quartz/js/darkmode.f77f63bb01d142b61d2c12fbb4418858.min.js></script>
<script src=https://hayul7805.github.io/quartz/js/util.a0ccf91e1937fe761a74da4946452710.min.js></script>
<link rel=preload href=https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.css as=style onload='this.onload=null,this.rel="stylesheet"' integrity=sha384-R4558gYOUz8mP9YWpZJjofhk+zx0AS11p36HnD2ZKj/6JR5z27gSSULCNHIRReVs crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.js integrity=sha384-z1fJDqw8ZApjGO3/unPWUPsIymfsJmyrDVWC8Tv/a1HeOtGmkwNd/7xUS0Xcnvsx crossorigin=anonymous></script>
<script defer src=https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/contrib/auto-render.min.js integrity=sha384-+XBljXPPiv+OzfbB3cVmLHf4hdUFHlWNZN5spNQ7rmHTXpd7WvJum6fIACpNNfIR crossorigin=anonymous></script>
<script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.2/dist/contrib/copy-tex.min.js integrity=sha384-ww/583aHhxWkz5DEVn6OKtNiIaLi2iBRNZXfJRiY1Ai7tnJ9UXpEsyvOITVpTl4A crossorigin=anonymous></script>
<script src=https://cdn.jsdelivr.net/npm/@floating-ui/core@1.2.1></script>
<script src=https://cdn.jsdelivr.net/npm/@floating-ui/dom@1.2.1></script>
<script async src=https://hayul7805.github.io/quartz/js/popover.aa9bc99c7c38d3ae9538f218f1416adb.min.js></script>
<script defer src=https://hayul7805.github.io/quartz/js/code-title.ce4a43f09239a9efb48fee342e8ef2df.min.js></script>
<script defer src=https://hayul7805.github.io/quartz/js/clipboard.2913da76d3cb21c5deaa4bae7da38c9f.min.js></script>
<script defer src=https://hayul7805.github.io/quartz/js/callouts.7723cac461d613d118ee8bb8216b9838.min.js></script>
<script>const SEARCH_ENABLED=!1,LATEX_ENABLED=!0,PRODUCTION=!0,BASE_URL="https://hayul7805.github.io/quartz/",fetchData=Promise.all([fetch("https://hayul7805.github.io/quartz/indices/linkIndex.218ccb5faaa00bee632cf650c213090d.min.json").then(e=>e.json()).then(e=>({index:e.index,links:e.links})),fetch("https://hayul7805.github.io/quartz/indices/contentIndex.72600786c410ab9f4ef5f51d8fa70104.min.json").then(e=>e.json())]).then(([{index:e,links:t},n])=>({index:e,links:t,content:n})),render=()=>{const e=new URL(BASE_URL),t=e.pathname,n=window.location.pathname,s=t==n;addCopyButtons(),addTitleToCodeBlocks(),addCollapsibleCallouts(),initPopover("https://hayul7805.github.io/quartz",!0);const o=document.getElementById("footer");if(o){const e=document.getElementById("graph-container");if(!e)return requestAnimationFrame(render);e.textContent="";const t=s&&!1;drawGraph("https://hayul7805.github.io/quartz",t,[{"/moc":"#4388cc"}],t?{centerForce:1,depth:-1,enableDrag:!0,enableLegend:!1,enableZoom:!0,fontSize:.5,linkDistance:1,opacityScale:3,repelForce:1,scale:1.4}:{centerForce:1,depth:1,enableDrag:!0,enableLegend:!1,enableZoom:!0,fontSize:.6,linkDistance:1,opacityScale:3,repelForce:2,scale:1.2})}var i=document.getElementsByClassName("mermaid");i.length>0&&import("https://unpkg.com/mermaid@9/dist/mermaid.esm.min.mjs").then(e=>{e.default.init()});function a(n){const e=n.target,t=e.className.split(" "),s=t.includes("broken"),o=t.includes("internal-link");plausible("Link Click",{props:{href:e.href,broken:s,internal:o,graph:!1}})}const r=document.querySelectorAll("a");for(link of r)link.className.includes("root-title")&&link.addEventListener("click",a,{once:!0})},init=(e=document)=>{addCopyButtons(),addTitleToCodeBlocks(),renderMathInElement(e.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1}],macros:{'â€™':"'"},throwOnError:!1})}</script><script type=module>
    import { attachSPARouting } from "https:\/\/hayul7805.github.io\/quartz\/js\/router.d6fe6bd821db9ea97f9aeefae814d8e7.min.js"
    attachSPARouting(init, render)
  </script><script defer data-domain=hayul7805.github.io/quartz src=https://plausible.io/js/script.js></script>
<script>window.plausible=window.plausible||function(){(window.plausible.q=window.plausible.q||[]).push(arguments)}</script></head><body><div id=search-container><div id=search-space><input autocomplete=off id=search-bar name=search type=text aria-label=Search placeholder="Search for something..."><div id=results-container></div></div></div><script src=https://cdn.jsdelivr.net/npm/flexsearch@0.7.21/dist/flexsearch.bundle.js integrity="sha256-i3A0NZGkhsKjVMzFxv3ksk0DZh3aXqu0l49Bbh0MdjE=" crossorigin=anonymous defer></script>
<script defer src=https://hayul7805.github.io/quartz/js/full-text-search.e6e2e0c213187ca0c703d6e2c7a77fcd.min.js></script><div class=singlePage><header><h1 id=page-title><a class=root-title href=https://hayul7805.github.io/quartz/>ğŸª´ Quartz 3.3</a></h1><div class=spacer></div><div id=search-icon><p>Search</p><svg tabindex="0" aria-labelledby="title desc" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 19.9 19.7"><title id="title">Search Icon</title><desc id="desc">Icon to open search</desc><g class="search-path" fill="none"><path stroke-linecap="square" d="M18.5 18.3l-5.4-5.4"/><circle cx="8" cy="8" r="7"/></g></svg></div><div class=darkmode><input class=toggle id=darkmode-toggle type=checkbox tabindex=-1>
<label id=toggle-label-light for=darkmode-toggle tabindex=-1><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" id="dayIcon" viewBox="0 0 35 35" style="enable-background:new 0 0 35 35"><title>Light Mode</title><path d="M6 17.5C6 16.672 5.328 16 4.5 16h-3C.672 16 0 16.672.0 17.5S.672 19 1.5 19h3C5.328 19 6 18.328 6 17.5zM7.5 26c-.414.0-.789.168-1.061.439l-2 2C4.168 28.711 4 29.086 4 29.5 4 30.328 4.671 31 5.5 31c.414.0.789-.168 1.06-.44l2-2C8.832 28.289 9 27.914 9 27.5 9 26.672 8.329 26 7.5 26zm10-20C18.329 6 19 5.328 19 4.5v-3C19 .672 18.329.0 17.5.0S16 .672 16 1.5v3C16 5.328 16.671 6 17.5 6zm10 3c.414.0.789-.168 1.06-.439l2-2C30.832 6.289 31 5.914 31 5.5 31 4.672 30.329 4 29.5 4c-.414.0-.789.168-1.061.44l-2 2C26.168 6.711 26 7.086 26 7.5 26 8.328 26.671 9 27.5 9zM6.439 8.561C6.711 8.832 7.086 9 7.5 9 8.328 9 9 8.328 9 7.5c0-.414-.168-.789-.439-1.061l-2-2C6.289 4.168 5.914 4 5.5 4 4.672 4 4 4.672 4 5.5c0 .414.168.789.439 1.06l2 2.001zM33.5 16h-3c-.828.0-1.5.672-1.5 1.5s.672 1.5 1.5 1.5h3c.828.0 1.5-.672 1.5-1.5S34.328 16 33.5 16zM28.561 26.439C28.289 26.168 27.914 26 27.5 26c-.828.0-1.5.672-1.5 1.5.0.414.168.789.439 1.06l2 2C28.711 30.832 29.086 31 29.5 31c.828.0 1.5-.672 1.5-1.5.0-.414-.168-.789-.439-1.061l-2-2zM17.5 29c-.829.0-1.5.672-1.5 1.5v3c0 .828.671 1.5 1.5 1.5s1.5-.672 1.5-1.5v-3C19 29.672 18.329 29 17.5 29zm0-22C11.71 7 7 11.71 7 17.5S11.71 28 17.5 28 28 23.29 28 17.5 23.29 7 17.5 7zm0 18c-4.136.0-7.5-3.364-7.5-7.5s3.364-7.5 7.5-7.5 7.5 3.364 7.5 7.5S21.636 25 17.5 25z"/></svg></label><label id=toggle-label-dark for=darkmode-toggle tabindex=-1><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" id="nightIcon" viewBox="0 0 100 100" style="enable-background='new 0 0 100 100'"><title>Dark Mode</title><path d="M96.76 66.458c-.853-.852-2.15-1.064-3.23-.534-6.063 2.991-12.858 4.571-19.655 4.571C62.022 70.495 50.88 65.88 42.5 57.5 29.043 44.043 25.658 23.536 34.076 6.47c.532-1.08.318-2.379-.534-3.23-.851-.852-2.15-1.064-3.23-.534-4.918 2.427-9.375 5.619-13.246 9.491-9.447 9.447-14.65 22.008-14.65 35.369.0 13.36 5.203 25.921 14.65 35.368s22.008 14.65 35.368 14.65c13.361.0 25.921-5.203 35.369-14.65 3.872-3.871 7.064-8.328 9.491-13.246C97.826 68.608 97.611 67.309 96.76 66.458z"/></svg></label></div></header><article><h1>Challenges and frontiers in abusive content detect</h1><p class=meta>Last updated
Dec 12, 2022
<a href=https://github.com/hayul7805/notes/paper-review/Challenges%20and%20frontiers%20in%20abusive%20content%20detect.md rel=noopener>Edit Source</a></p><ul class=tags><li><a href=https://hayul7805.github.io/quartz/tags/Hate-speech-detection/>Hate speech detection</a></li><li><a href=https://hayul7805.github.io/quartz/tags/generalization/>Generalization</a></li></ul><blockquote class=note-callout><p>Note</p><p>ì´ë²ˆì— ì •ë¦¬í•˜ëŠ” ë…¼ë¬¸ì€ &ldquo;abusive content detect&rdquo; ê³¼ì œê°€ ì–´ë–»ê²Œ ë°œì „í–ˆê³ , ì§€ê¸ˆ ë§ˆì£¼í•˜ê³  ìˆëŠ” ì–´ë ¤ì›€ì€ ë¬´ì—‡ì¸ì§€ ì†Œê°œí•˜ëŠ” ë…¼ë¬¸ì´ë‹¤.
í˜ì˜¤í‘œí˜„ íƒì§€ ê³¼ì œì™€ (ì™„ì „íˆëŠ” ì•„ë‹ˆì§€ë§Œ) ë¹„ìŠ·í•œ ê³¼ì œì´ê¸°ì— ë¹„ìŠ·í•œ ì–´ë ¤ì›€ë“¤ì„ ê³µìœ í•˜ê³  ìˆë‹¤. ì£¼ì„ ì‘ì—…ì˜ ì–´ë ¤ì›€, ê°œë… ì •ì˜ì˜ ì •í™•ì„± ë“±&mldr;
ê°œì¸ì ìœ¼ë¡œ ì¸ìƒ ê¹Šì€ ê²ƒì€ &lsquo;í›ˆë ¨ ë°ì´í„°ì™€ ë‹¤ë¥¸ ë„ë©”ì¸ì—ì„œ í…ŒìŠ¤íŠ¸ê°€ ì´ë£¨ì–´ì§€ë©´ ì„±ëŠ¥ì´ ì–´ë–»ê²Œ ë³€í• ì§€&rsquo;ë¥¼ ì†Œê°œí•˜ëŠ” íŒŒíŠ¸ì´ë‹¤.</p></blockquote><hr><blockquote><p>Developing robust systems to detect abuse is a crucial part of online content moderation and plays a fundamental role in creating an open, safe and accessible Internet.</p></blockquote><ul><li>ìš•ì„¤(abuse)ì„ íƒì§€í•˜ê¸° ìœ„í•œ ê°•ë ¥í•œ ì‹œìŠ¤í…œì„ ê°œë°œí•˜ëŠ” ê²ƒì€ ì˜¨ë¼ì¸ ì½˜í…ì¸  ì¡°ì •ì˜ ì¤‘ìš”í•œ ë¶€ë¶„ì´ë©° <strong>ê°œë°©ì ì´ê³  ì•ˆì „í•˜ë©° ì ‘ê·¼ ê°€ëŠ¥í•œ ì¸í„°ë„·ì„ ë§Œë“œëŠ” ë° ê·¼ë³¸ì ì¸ ì—­í• ì„ í•œë‹¤</strong>.</li></ul><blockquote><p>Advances in machine learning and NLP have led to marked improvements in abusive content detection systemsâ€™ performance (Fortuna & Nunes, 2018; Schmidt & Wiegand, 2017). For instance, in 2018 Pitsilis et al. trained a classification system on Waseem and Hovyâ€™s 16,000 tweet dataset and achieved an F-Score of 0.932, compared against Waseem and Hovyâ€™s original 0.739; a 20-point increase (Pitsilis, Ramampiaro, & Langseth, 2018; Waseem & Hovy, 2016).</p></blockquote><ul><li><strong>ë¨¸ì‹  ëŸ¬ë‹ê³¼ NLPì˜ ë°œì „ì€ ëª¨ìš• ì½˜í…ì¸  ê°ì§€ ì‹œìŠ¤í…œì˜ ì„±ëŠ¥ì„ í˜„ì €í•˜ê²Œ í–¥ìƒì‹œì¼°ë‹¤(Fortuna & Nunes, 2018; Schmidt & Wiegand, 2017).</strong> ì˜ˆë¥¼ ë“¤ì–´, 2018ë…„ Pitsilis ë“±ì€ Wasemê³¼ Hovyì˜ 16,000ê°œì˜ íŠ¸ìœ— ë°ì´í„° ì„¸íŠ¸ì— ëŒ€í•œ ë¶„ë¥˜ ì‹œìŠ¤í…œì„ í›ˆë ¨í•˜ê³  Wasemê³¼ Hovyì˜ ì›ë˜ 0.739ì™€ ë¹„êµí•˜ì—¬ 0.932ì˜ F-Scoreë¥¼ ë‹¬ì„±í–ˆë‹¤(Pitsilis, Ramampiaro, & Langseth, 2018; Wasem & Hovy, 2016).</li></ul><blockquote><p>Researchers have also addressed numerous tasks beyond binary abusive content classification, including identifying the target of abuse and its strength as well as automatically moderating content (Burnap & Williams, 2016; Davidson, Warmsley, Macy, & Weber, 2017; Santos, Melnyk, & Padhi, 2018).</p></blockquote><ul><li>ì—°êµ¬ìë“¤ì€ ë˜í•œ í•™ëŒ€ ëŒ€ìƒì„ ì‹ë³„í•˜ëŠ” ê²ƒë¿ë§Œ ì•„ë‹ˆë¼ ì½˜í…ì¸  ìë™ ì¡°ì ˆì„ í¬í•¨í•˜ì—¬ ì´ì§„ ìš•ì„¤ ì½˜í…ì¸  ë¶„ë¥˜ë¥¼ ë„˜ì–´ ìˆ˜ë§ì€ ê³¼ì œë¥¼ í•´ê²°í–ˆë‹¤(Burnap & Williams, 2016; Davidson, Warmsley, Macy, Weber, 2017; Santos, Melnyk, & Padhi, 2018).</li></ul><blockquote><p>(â€¦) what type of abusive content it is identified as. This is a social and theoretical task: <strong>there is no objectively â€˜correctâ€™ definition</strong> or single set of pre-established criteria which can be applied.</p></blockquote><ul><li>(&mldr;) ì–´ë–¤ ìœ í˜•ì˜ ìš•ì„¤ ì½˜í…ì¸ ë¡œ ì‹ë³„ë˜ëŠ”ì§€ë„ ì¤‘ìš”í•˜ë‹¤. ì´ëŸ¬í•œ ë¶„ë¥˜ëŠ” ì‚¬íšŒì ì´ê³  ì´ë¡ ì ì¸ ê³¼ì œì´ê¸°ì—, <strong>ê°ê´€ì ìœ¼ë¡œ &lsquo;ì˜¬ë°”ë¥¸&rsquo; ì •ì˜ë‚˜ ì ìš©í•  ìˆ˜ ìˆëŠ” ì‚¬ì „ ì„¤ì •ëœ ê¸°ì¤€ì˜ ë‹¨ì¼ ì§‘í•©ì€ ì—†ë‹¤.</strong></li></ul><blockquote><p>Detecting abusive content generically is an important aspiration for the field. <strong>However, it is very difficult because abusive content is so varied.</strong> Research which purports to address the generic task of detecting abuse is typically actually addressing something much more specific. This can often be discerned from the datasets, which may contain systematic biases towards certain types and targets of abuse. For instance, the dataset by Davidson et al. is used widely for tasks described generically as abusive content detection yet it is highly skewed towards racism and sexism (Davidson et al., 2017).</p></blockquote><ul><li>ìš•ì„¤ ì½˜í…ì¸ ë¥¼ ì „ë°˜ì ìœ¼ë¡œ ê°ì§€í•˜ëŠ” ê²ƒì€ í˜„ì¥ì˜ ì¤‘ìš”í•œ í¬ë¶€ë‹¤. í•˜ì§€ë§Œ ì´ëŠ” ìš•ì„¤ì˜ ë‚´ìš©ì´ ë‹¤ì–‘í•˜ê¸° ë•Œë¬¸ì— ë§¤ìš° ì–´ë µë‹¤. <strong>ìš•ì„¤ì„ íƒì§€í•˜ëŠ” ì¼ë°˜ì ì¸ ê³¼ì œë¥¼ í•´ê²°í•œë‹¤ê³  ì£¼ì¥í•˜ëŠ” ì—°êµ¬ëŠ” ì¼ë°˜ì ìœ¼ë¡œ í›¨ì”¬ ë” êµ¬ì²´ì ì¸ ê²ƒ(specific)ì„ ë‹¤ë£¨ê³  ìˆë‹¤.</strong> ì´ê²ƒì€ ì¢…ì¢… ë°ì´í„° ì„¸íŠ¸ì—ì„œ ì‹ë³„ë  ìˆ˜ ìˆìœ¼ë©°, ì´ëŠ” íŠ¹ì • ìœ í˜• ë° ìš•ì„¤ ëŒ€ìƒì— ëŒ€í•œ ì²´ê³„ì ì¸ í¸ê²¬ì„ í¬í•¨í•  ìˆ˜ ìˆë‹¤. <strong>ì˜ˆë¥¼ ë“¤ì–´, Davidson ë“±ì˜ ë°ì´í„° ì„¸íŠ¸ëŠ” ì¼ë°˜ì ìœ¼ë¡œ ìš•ì„¤ ì½˜í…ì¸  íƒì§€ë¡œ ì„¤ëª…ë˜ëŠ” ì‘ì—…ì— ë„ë¦¬ ì‚¬ìš©ë˜ì§€ë§Œ ì¸ì¢…ì°¨ë³„ê³¼ ì„±ì°¨ë³„ ìª½ìœ¼ë¡œ í¬ê²Œ ì¹˜ìš°ì³ ìˆë‹¤(Davidson ë“±, 2017).</strong></li></ul><blockquote><p>Waseem et al. suggest that one of the main differences between subtasks is whether content is â€˜directed towards a specific entity or is directed towards a generalized groupâ€™ (Waseem et al., 2017).</p></blockquote><ul><li><code>Waseem et al.</code>ì€ í•˜ìœ„ ì‘ì—… ê°„ì˜ ì£¼ìš” ì°¨ì´ì  ì¤‘ í•˜ë‚˜ëŠ” ì½˜í…ì¸ ê°€ &lsquo;íŠ¹ì • ì—”í‹°í‹°ë¥¼ ì§€í–¥í•˜ëŠ”ì§€, ì•„ë‹ˆë©´ ì¼ë°˜í™”ëœ ê·¸ë£¹ì„ ì§€í–¥í•˜ëŠ”ì§€&rsquo;ë¼ê³  ì œì•ˆí•œë‹¤(Wasee et al., 2017).</li></ul><blockquote><p>A key distinction is whether abuse is explicit or implicit (Waseem et al., 2017; Zampieri et al., 2019).</p></blockquote><blockquote><p>Some of the main problems are (1) researchers use terms which are not well-defined, (2) different concepts and terms are used across the field for similar work, and (3) the terms which are used are theoretically problematic.</p></blockquote><ul><li>ì£¼ìš” ë¬¸ì œ ì¤‘ ì¼ë¶€ëŠ” (1) ì—°êµ¬ìë“¤ì´ ì˜ ì •ì˜ë˜ì§€ ì•Šì€ ìš©ì–´ë¥¼ ì‚¬ìš©í•˜ê³ , (2) ìœ ì‚¬í•œ ì‘ì—…ì— ëŒ€í•´ í˜„ì¥ ì „ë°˜ì— ê±¸ì³ ë‹¤ë¥¸ ê°œë…ê³¼ ìš©ì–´ë¥¼ ì‚¬ìš©í•˜ë©°, (3) ì‚¬ìš©ë˜ëŠ” ìš©ì–´ê°€ ì´ë¡ ì ìœ¼ë¡œ ë¬¸ì œê°€ ìˆë‹¤ëŠ” ê²ƒì´ë‹¤.</li></ul><blockquote><p><strong>Annotation.</strong>
Annotation is a notoriously difficult task, reflected in the low levels of inter-annotator agreement reported by most publications, particularly on more complex multi-class tasks (Sanguinetti, Poletto, Bosco, Patti, & Stranisci, 2018). Noticeably, van Aken suggests that Davidson et al.â€™s widely used hate and offensive language dataset has up to 10% of its data mislabeled (van Aken et al., 2018).</p></blockquote><ul><li>ì£¼ì„ì€ ì•…ëª…ë†’ê²Œ ì–´ë ¤ìš´ ì‘ì—…ìœ¼ë¡œ, íŠ¹íˆ ë” ë³µì¡í•œ ë‹¤ì¤‘ í´ë˜ìŠ¤ ì‘ì—…ì— ëŒ€í•´ ëŒ€ë¶€ë¶„ì˜ ì—°êµ¬ë“¤ì—ì„œ ë³´ê³ í•œ ì£¼ì„ ê°„ í•©ì˜(inter-annotator agreement)ì˜ ë‚®ì€ ìˆ˜ì¤€ì— ë°˜ì˜ëœë‹¤(Sanguinetti, Poletto, Bosco, Patti, & Stranisci, 2018). ë…íŠ¹í•˜ê²Œ, <strong>ë°˜ ì—ì´ì¼„ì€ ë°ì´ë¹„ë“œìŠ¨ ë“±ì˜ ë„ë¦¬ ì‚¬ìš©ë˜ëŠ” í˜ì˜¤ ë° ê³µê²©ì ì¸ ì–¸ì–´ ë°ì´í„° ì„¸íŠ¸ê°€ ìµœëŒ€ 10%ì˜ ë°ì´í„° ë ˆì´ë¸”ì´ ì˜ëª» ì§€ì •ë˜ì—ˆìŒì„ ì‹œì‚¬í•œë‹¤(ë°˜ ì—ì´ì¼„ ì™¸, 2018).</strong></li></ul><blockquote><p>Few publications provide details of their annotation process or annotation guidelines. Providing such information is the norm in social scientific research and is viewed as an integral part of verifying othersâ€™ findings and robustness (Bucy & Holbert, 2013). In line with the recommendations of Sabou et al., we advocate that annotation guidelines and processes are shared where possible (Sabou, Bontcheva, Derczynski, & Scharl, 2014) and that the field also works to develop best practices.</p></blockquote><ul><li>ì£¼ì„ í”„ë¡œì„¸ìŠ¤ ë˜ëŠ” ì£¼ì„ ì§€ì¹¨ì— ëŒ€í•œ ìì„¸í•œ ë‚´ìš©ì„ ì œê³µí•˜ëŠ” ì—°êµ¬ë“¤ì€ ê±°ì˜ ì—†ë‹¤. <strong>ì´ëŸ¬í•œ ì •ë³´ë¥¼ ì œê³µí•˜ëŠ” ê²ƒì€ ì‚¬íšŒê³¼í•™ ì—°êµ¬ì˜ í‘œì¤€ì´ë©°</strong>, íƒ€ì¸ì˜ ë°œê²¬ê³¼ ê²¬ê³ ì„±ì„ ê²€ì¦í•˜ëŠ” ë° í•„ìˆ˜ì ì¸ ë¶€ë¶„ìœ¼ë¡œ ê°„ì£¼ëœë‹¤(Bucy & Holbert, 2013). <strong>Sabou ë“±ì˜ ê¶Œê³ ì— ë”°ë¼, ìš°ë¦¬ëŠ” ì£¼ì„ ì§€ì¹¨ê³¼ í”„ë¡œì„¸ìŠ¤ê°€ ê°€ëŠ¥í•œ ê³³ì—ì„œ ê³µìœ ë˜ê³ (Sabou, Bontcheva, Derczynski, & Scharl, 2014) ì´ ë¶„ì•¼ë„ ëª¨ë²” ì‚¬ë¡€ë¥¼ ê°œë°œí•˜ê¸° ìœ„í•´ ë…¸ë ¥í•´ì•¼ í•œë‹¤ê³  ì£¼ì¥í•œë‹¤.</strong></li></ul><blockquote><p>Ensuring that abusive content detection systems can be applied across different domains is one of the most difficult but also important frontiers in existing research. Thus far, efforts to address this has been unsuccessful. Burnap and Williams train systems on one type of hate speech (e.g. racism) and apply them to another (e.g. sexism) and find that performance drops considerably (Burnap & Williams, 2016)</p></blockquote><ul><li>ìš•ì„¤ ì½˜í…ì¸  íƒì§€ ì‹œìŠ¤í…œì´ ì„œë¡œ ë‹¤ë¥¸ ì˜ì—­ì— ê±¸ì³ ì ìš©ë  ìˆ˜ ìˆë„ë¡ ë³´ì¥í•˜ëŠ” ê²ƒì€ ê¸°ì¡´ ì—°êµ¬ì—ì„œ ê°€ì¥ ì–´ë µì§€ë§Œ ì¤‘ìš”í•œ ë¶„ì•¼ ì¤‘ í•˜ë‚˜ì´ë‹¤. ì§€ê¸ˆê¹Œì§€, ì´ê²ƒì„ í•´ê²°í•˜ë ¤ëŠ” ë…¸ë ¥ì€ ì„±ê³µí•˜ì§€ ëª»í–ˆë‹¤. <strong>Burnapê³¼ WilliamsëŠ” í•œ ìœ í˜•ì˜ í˜ì˜¤ ë°œì–¸(ì˜ˆ: ì¸ì¢…ì°¨ë³„)ì— ëŒ€í•´ ì‹œìŠ¤í…œì„ í›ˆë ¨ì‹œí‚¤ê³  ë‹¤ë¥¸ ìœ í˜•ì˜ í˜ì˜¤ ë°œì–¸(ì˜ˆ: ì„±ì°¨ë³„)ì— ì ìš©í•˜ë©° ì„±ëŠ¥ì´ ìƒë‹¹íˆ ë–¨ì–´ì§„ë‹¤ëŠ” ê²ƒì„ ë°œê²¬í•œë‹¤(Burnap & Williams, 2016).</strong></li></ul><blockquote><p>Karan and Å najder use a simple methodology to show the huge differences in performance when applying classifiers on different datasets without domain-specific tuning (Karan & Å najder, 2018). Noticeably, in the EVALITA hate speech detection shared task, participants were asked to (1) train and test a system on Twitter data, (2) on Facebook data and (3) to train on Twitter and test on Facebook (and vice versa). <strong>Even the best performing teams reported their systems scored around 10 to 15 F1 points fewer on the cross-domain task.</strong></p></blockquote><ul><li>Karanê³¼ ShnajderëŠ” ë„ë©”ì¸ë³„ íŠœë‹ ì—†ì´ ì„œë¡œ ë‹¤ë¥¸ ë°ì´í„° ì„¸íŠ¸ì— ë¶„ë¥˜ê¸°ë¥¼ ì ìš©í•  ë•Œ ì„±ëŠ¥ì—ì„œ í° ì°¨ì´ë¥¼ ë³´ì—¬ì£¼ê¸° ìœ„í•´ ê°„ë‹¨í•œ ë°©ë²•ë¡ ì„ ì‚¬ìš©í•œë‹¤(Karan & Shnajder, 2018). ëˆˆì— ë„ê²Œ, EVALITA í˜ì˜¤ ë°œì–¸ íƒì§€ ê³µìœ  ì‘ì—…ì—ì„œ, <strong>ì°¸ê°€ìë“¤ì—ê²Œ (1) íŠ¸ìœ„í„° ë°ì´í„°ì— ëŒ€í•œ ì‹œìŠ¤í…œ í›ˆë ¨ ë° í…ŒìŠ¤íŠ¸, (2) í˜ì´ìŠ¤ë¶ ë°ì´í„°ì— ëŒ€í•œ ì‹œìŠ¤í…œ í›ˆë ¨ ë° í…ŒìŠ¤íŠ¸, (3) íŠ¸ìœ„í„°ì— ëŒ€í•œ í›ˆë ¨ ë° í˜ì´ìŠ¤ë¶ì—ì„œ í…ŒìŠ¤íŠ¸(ë° ê·¸ ë°˜ëŒ€)ë¥¼ ìš”ì²­í•˜ì˜€ë‹¤.</strong> ìµœê³ ì˜ ì„±ê³¼ë¥¼ ê±°ë‘” íŒ€ë“¤ì¡°ì°¨ ê·¸ë“¤ì˜ ì‹œìŠ¤í…œì´ êµì°¨ ë„ë©”ì¸ ì‘ì—…ì—ì„œ ì•½ 10-15ì˜ F1 ì ìˆ˜ë¥¼ ë” ì ê²Œ ë°›ì•˜ë‹¤ê³  ë³´ê³ í–ˆë‹¤.</li></ul><hr><blockquote class=info-callout><p>Reference</p><p>Bertie Vidgen, Alex Harris, Dong Nguyen, Rebekah Tromble, Scott Hale, and Helen Margetts. 2019.Â 
<a href=https://aclanthology.org/W19-3509 rel=noopener>Challenges and frontiers in abusive content detection</a>. InÂ <em>Proceedings of the Third Workshop on Abusive Language Online</em>, pages 80â€“93, Florence, Italy. Association for Computational Linguistics.</p></blockquote></article><hr><div class=page-end id=footer><div class=backlinks-container><h3>Backlinks</h3><ul class=backlinks><li><a href=/quartz/notes/paper-review/ data-ctx="ğŸ“„ Challenges and frontiers in abusive content detect" data-src=/notes/paper-review class=internal-link>ğŸ“‘ Paper Review</a></li></ul></div><div><script async src=https://cdn.jsdelivr.net/npm/d3@6.7.0/dist/d3.min.js integrity="sha256-+7jaYCp29O1JusNWHaYtgUn6EhuP0VaFuswhNV06MyI=" crossorigin=anonymous></script><h3>Interactive Graph</h3><div id=graph-container></div><style>:root{--g-node:var(--secondary);--g-node-active:var(--primary);--g-node-inactive:var(--visited);--g-link:var(--outlinegray);--g-link-active:#5a7282}</style><script src=https://hayul7805.github.io/quartz/js/graph.6579af7b10c818dbd2ca038702db0224.js></script></div></div><div id=contact_buttons><footer><p>Made by Hayul Park using <a href=https://github.com/jackyzha0/quartz>Quartz</a>, Â© 2023</p><ul><li><a href=https://hayul7805.github.io/quartz/>Home</a></li><li><a href=https://www.linkedin.com/in/hayulpark/>Linkedin</a></li></ul></footer></div></div></body></html>