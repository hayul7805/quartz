<!doctype html><html lang=en><head><meta charset=utf-8><meta name=description content="[!note] Reference
Steve Durairaj Swamy, Anupam Jamatia, and BjÃ¶rn GambÃ¤ck. 2019.Â Studying Generalisability across Abusive Language Detection Datasets. InÂ Proceedings of the 23rd Conference on Computational Natural Language Learning (CoNLL), pages 940â€“950, Hong Kong, China."><title>Studying Generalisability Across Abusive Language Detection Datasets</title><meta name=viewport content="width=device-width,initial-scale=1"><link rel="shortcut icon" type=image/png href=https://hayul7805.github.io/quartz//icon.png><link href=https://hayul7805.github.io/quartz/styles.7153093e4d1bbb584a28469cadfa3f88.min.css rel=stylesheet><link href=https://hayul7805.github.io/quartz/styles/_light_syntax.86a48a52faebeaaf42158b72922b1c90.min.css rel=stylesheet id=theme-link><script src=https://hayul7805.github.io/quartz/js/darkmode.f77f63bb01d142b61d2c12fbb4418858.min.js></script>
<script src=https://hayul7805.github.io/quartz/js/util.9825137f5e7825e8553c68ce39ac9e44.min.js></script>
<link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.css integrity=sha384-R4558gYOUz8mP9YWpZJjofhk+zx0AS11p36HnD2ZKj/6JR5z27gSSULCNHIRReVs crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.js integrity=sha384-z1fJDqw8ZApjGO3/unPWUPsIymfsJmyrDVWC8Tv/a1HeOtGmkwNd/7xUS0Xcnvsx crossorigin=anonymous></script>
<script defer src=https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/contrib/auto-render.min.js integrity=sha384-+XBljXPPiv+OzfbB3cVmLHf4hdUFHlWNZN5spNQ7rmHTXpd7WvJum6fIACpNNfIR crossorigin=anonymous></script>
<script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.2/dist/contrib/copy-tex.min.js integrity=sha384-ww/583aHhxWkz5DEVn6OKtNiIaLi2iBRNZXfJRiY1Ai7tnJ9UXpEsyvOITVpTl4A crossorigin=anonymous></script>
<script src=https://unpkg.com/@floating-ui/core@0.7.3></script>
<script src=https://unpkg.com/@floating-ui/dom@0.5.4></script>
<script src=https://hayul7805.github.io/quartz/js/popover.53ad9a087e3feeaaa12b63bfd02d923b.min.js></script>
<script src=https://hayul7805.github.io/quartz/js/code-title.b35124ad8db0ba37162b886afb711cbc.min.js></script>
<script src=https://hayul7805.github.io/quartz/js/clipboard.c20857734e53a3fb733b7443879efa61.min.js></script>
<script src=https://hayul7805.github.io/quartz/js/callouts.7723cac461d613d118ee8bb8216b9838.min.js></script>
<script>const BASE_URL="https://hayul7805.github.io/quartz/",fetchData=Promise.all([fetch("https://hayul7805.github.io/quartz/indices/linkIndex.f03701aaac55b27abfc497078942c000.min.json").then(e=>e.json()).then(e=>({index:e.index,links:e.links})),fetch("https://hayul7805.github.io/quartz/indices/contentIndex.e63c7a8629cd435daba6de35d95848bc.min.json").then(e=>e.json())]).then(([{index:e,links:t},n])=>({index:e,links:t,content:n})),render=()=>{const e=new URL(BASE_URL),t=e.pathname,n=window.location.pathname,s=t==n;addCopyButtons(),addTitleToCodeBlocks(),addCollapsibleCallouts(),initPopover("https://hayul7805.github.io/quartz",!0,!0);const o=document.getElementById("footer");if(o){const e=document.getElementById("graph-container");if(!e)return requestAnimationFrame(render);e.textContent="";const t=s&&!1;drawGraph("https://hayul7805.github.io/quartz",t,[{"/moc":"#4388cc"}],t?{centerForce:1,depth:-1,enableDrag:!0,enableLegend:!1,enableZoom:!0,fontSize:.5,linkDistance:1,opacityScale:3,repelForce:1,scale:1.4}:{centerForce:1,depth:1,enableDrag:!0,enableLegend:!1,enableZoom:!0,fontSize:.6,linkDistance:1,opacityScale:3,repelForce:2,scale:1.2})}},init=(e=document)=>{addCopyButtons(),addTitleToCodeBlocks(),renderMathInElement(e.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1}],macros:{'â€™':"'"},throwOnError:!1})}</script><script type=module>
    import { attachSPARouting } from "https:\/\/hayul7805.github.io\/quartz\/js\/router.9d4974281069e9ebb189f642ae1e3ca2.min.js"
    attachSPARouting(init, render)
  </script></head><body><div id=search-container><div id=search-space><input autocomplete=off id=search-bar name=search type=text aria-label=Search placeholder="Search for something..."><div id=results-container></div></div></div><script src=https://cdn.jsdelivr.net/npm/flexsearch@0.7.21/dist/flexsearch.bundle.js integrity="sha256-i3A0NZGkhsKjVMzFxv3ksk0DZh3aXqu0l49Bbh0MdjE=" crossorigin=anonymous defer></script>
<script defer src=https://hayul7805.github.io/quartz/js/full-text-search.24827f874defbbc6d529926cbfcfb493.min.js></script><div class=singlePage><header><h1 id=page-title><a href=https://hayul7805.github.io/quartz/>ğŸŒ± Hayul's digital garden</a></h1><div class=spacer></div><div id=search-icon><p>Search</p><svg tabindex="0" aria-labelledby="title desc" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 19.9 19.7"><title id="title">Search Icon</title><desc id="desc">Icon to open search</desc><g class="search-path" fill="none"><path stroke-linecap="square" d="M18.5 18.3l-5.4-5.4"/><circle cx="8" cy="8" r="7"/></g></svg></div><div class=darkmode><input class=toggle id=darkmode-toggle type=checkbox tabindex=-1>
<label id=toggle-label-light for=darkmode-toggle tabindex=-1><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" id="dayIcon" viewBox="0 0 35 35" style="enable-background:new 0 0 35 35"><title>Light Mode</title><path d="M6 17.5C6 16.672 5.328 16 4.5 16h-3C.672 16 0 16.672.0 17.5S.672 19 1.5 19h3C5.328 19 6 18.328 6 17.5zM7.5 26c-.414.0-.789.168-1.061.439l-2 2C4.168 28.711 4 29.086 4 29.5 4 30.328 4.671 31 5.5 31c.414.0.789-.168 1.06-.44l2-2C8.832 28.289 9 27.914 9 27.5 9 26.672 8.329 26 7.5 26zm10-20C18.329 6 19 5.328 19 4.5v-3C19 .672 18.329.0 17.5.0S16 .672 16 1.5v3C16 5.328 16.671 6 17.5 6zm10 3c.414.0.789-.168 1.06-.439l2-2C30.832 6.289 31 5.914 31 5.5 31 4.672 30.329 4 29.5 4c-.414.0-.789.168-1.061.44l-2 2C26.168 6.711 26 7.086 26 7.5 26 8.328 26.671 9 27.5 9zM6.439 8.561C6.711 8.832 7.086 9 7.5 9 8.328 9 9 8.328 9 7.5c0-.414-.168-.789-.439-1.061l-2-2C6.289 4.168 5.914 4 5.5 4 4.672 4 4 4.672 4 5.5c0 .414.168.789.439 1.06l2 2.001zM33.5 16h-3c-.828.0-1.5.672-1.5 1.5s.672 1.5 1.5 1.5h3c.828.0 1.5-.672 1.5-1.5S34.328 16 33.5 16zM28.561 26.439C28.289 26.168 27.914 26 27.5 26c-.828.0-1.5.672-1.5 1.5.0.414.168.789.439 1.06l2 2C28.711 30.832 29.086 31 29.5 31c.828.0 1.5-.672 1.5-1.5.0-.414-.168-.789-.439-1.061l-2-2zM17.5 29c-.829.0-1.5.672-1.5 1.5v3c0 .828.671 1.5 1.5 1.5s1.5-.672 1.5-1.5v-3C19 29.672 18.329 29 17.5 29zm0-22C11.71 7 7 11.71 7 17.5S11.71 28 17.5 28 28 23.29 28 17.5 23.29 7 17.5 7zm0 18c-4.136.0-7.5-3.364-7.5-7.5s3.364-7.5 7.5-7.5 7.5 3.364 7.5 7.5S21.636 25 17.5 25z"/></svg></label><label id=toggle-label-dark for=darkmode-toggle tabindex=-1><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" id="nightIcon" viewBox="0 0 100 100" style="enable-background='new 0 0 100 100'"><title>Dark Mode</title><path d="M96.76 66.458c-.853-.852-2.15-1.064-3.23-.534-6.063 2.991-12.858 4.571-19.655 4.571C62.022 70.495 50.88 65.88 42.5 57.5 29.043 44.043 25.658 23.536 34.076 6.47c.532-1.08.318-2.379-.534-3.23-.851-.852-2.15-1.064-3.23-.534-4.918 2.427-9.375 5.619-13.246 9.491-9.447 9.447-14.65 22.008-14.65 35.369.0 13.36 5.203 25.921 14.65 35.368s22.008 14.65 35.368 14.65c13.361.0 25.921-5.203 35.369-14.65 3.872-3.871 7.064-8.328 9.491-13.246C97.826 68.608 97.611 67.309 96.76 66.458z"/></svg></label></div></header><article><h1>Studying Generalisability Across Abusive Language Detection Datasets</h1><p class=meta>Last updated
Nov 5, 2022</p><ul class=tags></ul><aside class=mainTOC><details><summary>Table of Contents</summary><nav id=TableOfContents><ol><li><a href=#previous-work>Previous Work</a></li><li><a href=#preliminary-feature-and-model-study>Preliminary Feature and Model Study</a></li><li><a href=#cross-dataset-training-and-testing>Cross-Dataset Training and Testing</a></li><li><a href=#discussion-and-conclusion>Discussion and Conclusion</a></li></ol></nav></details></aside><blockquote class=note-callout><p>Reference</p><p>Steve Durairaj Swamy, Anupam Jamatia, and BjÃ¶rn GambÃ¤ck. 2019.Â 
<a href=https://aclanthology.org/K19-1088 rel=noopener>Studying Generalisability across Abusive Language Detection Datasets</a>. InÂ <em>Proceedings of the 23rd Conference on Computational Natural Language Learning (CoNLL)</em>, pages 940â€“950, Hong Kong, China. Association for Computational Linguistics.</p></blockquote><a href=#previous-work><h2 id=previous-work><span class=hanchor arialabel=Anchor># </span>Previous Work</h2></a><blockquote><p>Abusive language detection has served as an umbrella term for a wide variety of subtasks. Research in the field has typically focused on a particular subtask: Hate Speech (Davidson et al., 2017; Founta et al., 2018; Gao and Huang, 2017; Golbeck et al., 2017), Sexism/Racism (Waseem and Hovy, 2016), Cyberbullying (Xu et al., 2012; Dadvar et al., 2013), Trolling and Aggression (Kumar et al., 2018a), and so on.
Datasets for these tasks have been collected from various social media platforms, such as Twitter (Waseem and Hovy, 2016; Davidson et al., 2017; Founta et al., 2018; Burnap and Williams, 2015; Golbeck et al., 2017), Facebook (Kumar et al., 2018a), Instagram (Hosseinmardi et al., 2015; Zhong et al., 2016), Yahoo! (Nobata et al., 2016; Djuric et al., 2015; Warner and Hirschberg, 2012), YouTube (Dinakar et al., 2011), and Wikipedia (Wulczyn et al., 2017), with annotation typically carried out on crowdsourcing platforms such as CrowdFlower (Figure Eight)1 and Amazon Mechanical Turk.</p></blockquote><ul><li>Abusive language detectionì— ëŒ€í•œ í•´ì™¸ ì—°êµ¬ ë ˆí¼ëŸ°ìŠ¤ê°€ ì˜ ì„¤ëª…ë˜ì–´ ìˆë‹¤.</li></ul><blockquote><p>In the â€˜OffensEvalâ€™ shared task (Zampieri et al., 2019b), the use of contextual embeddings such as BERT (Devlin et al., 2018) and ELMo (Peters et al., 2018) exhibited the best results.</p></blockquote><ul><li>BERTê°€ ë“±ì¥í•˜ê³  íƒì§€ ì—°êµ¬ì— ì“°ì´ê¸° ì‹œì‘.</li></ul><p>#key-observation</p><blockquote><p>Generalisability of a model has also come under considerable scrutiny. Works such as Karan and Å najder (2018) and GrÃ¶ndahl et al. (2018) have shown that <strong>models trained on one dataset tend to perform well only when tested on the same dataset.</strong></p></blockquote><ul><li>ì´ ë¶€ë¶„ì´ ë‚´ ì—°êµ¬ì˜ í•µì‹¬ê³¼ ê´€ë ¨ì´ ê¹Šë‹¤.</li></ul><blockquote><p>Additionally, GrÃ¶ndahl et al. (2018) showed how adversarial methods such as typos and word changes could bypass existing state-of- the-art abusive language detection systems.</p></blockquote><ul><li>&ldquo;All you need is â€œloveâ€: Evading hate speech detection&rdquo; ë…¼ë¬¸ ì €ìì´ë‹¤.</li></ul><blockquote><p>Fortuna et al. (2018) concurred, stating that although models perform better on the data they are trained on, slightly improved performance can be obtained when adding more training data from other social media.</p></blockquote><ul><li>Fortuna et al. (2018) ì—°êµ¬ë„ ìˆì—ˆêµ¬ë‚˜. ë‹¤ë¥¸ ë„ë©”ì¸ì—ì„œ ìˆ˜ì§‘í•œ ë°ì´í„°ë¥¼ ë” ì¶”ê°€í•´ í›ˆë ¨ì‹œí‚¤ë©´ ë” ì¢‹ì€ ì„±ëŠ¥ì„ ì–»ê²Œ ëœë‹¤ê³  í–ˆì—ˆë„¤. ì§€ê¸ˆì˜ ì¼ë°˜í™” ê°€ëŠ¥ì„±ì— ëŒ€í•œ ë…¼ì˜ê°€ ì—¬ê¸°ì—ì„œ ì¶œë°œí–ˆë‹¤.</li></ul><a href=#preliminary-feature-and-model-study><h2 id=preliminary-feature-and-model-study><span class=hanchor arialabel=Anchor># </span>Preliminary Feature and Model Study</h2></a><blockquote><p>However, fine-tuning was carried out on the mod- elsâ€™ hyper-parameters, such as sequence length, drop out, and class weights. Test and training sets were created for each dataset by performing a stratified split of 20% vs 80%, with the larger part used for training the models. The training sets were further subdivided, keeping 1/8 shares of them as separate validation sets during devel- opment and fine-tuning of the hyper-parameters.</p></blockquote><ul><li><strong>ê·¸ëŸ¬ë‚˜ ì‹œí€€ìŠ¤ ê¸¸ì´, ë“œë¡­ì•„ì›ƒ ë° í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ì™€ ê°™ì€ ëª¨ë¸ì˜ ì´ˆ ë§¤ê°œ ë³€ìˆ˜ì— ëŒ€í•´ ë¯¸ì„¸ ì¡°ì •ì´ ìˆ˜í–‰ë˜ì—ˆë‹¤. í…ŒìŠ¤íŠ¸ ë° í›ˆë ¨ ì„¸íŠ¸ëŠ” ê° ë°ì´í„° ì„¸íŠ¸ì— ëŒ€í•´ 20% ëŒ€ 80%ì˜ ê³„ì¸µí™”ëœ ë¶„í• ì„ ìˆ˜í–‰í•˜ì˜€ê³ , ì´í›„ ë” í° ë¶€ë¶„ì„ ëª¨ë¸ í›ˆë ¨ì— ì‚¬ìš©í•˜ì˜€ë‹¤.</strong> í›ˆë ¨ ì„¸íŠ¸ëŠ” ë”ìš± ì„¸ë¶„í™”ë˜ì–´ í•˜ì´í¼ íŒŒë¼ë¯¸í„°ì˜ ê°œë°œ ë° ë¯¸ì„¸ ì¡°ì • ì¤‘ì— 1/8 ê³µìœ ë¥¼ ë³„ë„ì˜ ê²€ì¦ ì„¸íŠ¸ë¡œ ìœ ì§€í•˜ì˜€ë‹¤.</li><li>ëª¨ë¸ í›ˆë ¨ì— ëŒ€í•´ì„œëŠ” ì´ë ‡ê²Œ ì„¤ëª…í•˜ë©´ ë˜ê² ë‹¤.</li></ul><blockquote><p>The best models used a learning rate of eâˆ’5 and batch size 32 with varying maximum sequence lengths between 60 and 70. Other parameters worth mentioning are the number of epochs and the Linear Warm-up Proportion.</p></blockquote><ul><li>ëª¨ë¸ í•˜ì´í¼íŒŒë¼ë¯¸í„°ì˜ ê²½ìš°ì—ëŠ” ì´ë ‡ê²Œ í‘œí˜„í•˜ë©´ ëœë‹¤.</li><li>ì–´ë¼, ê·¸ëŸ°ë° ì´ê±° ë³´ë‹¤ë³´ë‹ˆ
<a href=/quartz/notes/On-Cross-Dataset-Generalization-in-Automatic-Detection-of-Online-Abuse/ rel=noopener class=internal-link data-src=/quartz/notes/On-Cross-Dataset-Generalization-in-Automatic-Detection-of-Online-Abuse/>On Cross-Dataset Generalization in Automatic Detection of Online Abuse</a> ì´ë‘ ì„¤ëª…ì´ ë˜‘ê°™ë‹¤.</li></ul><p><img src=https://hayul7805.github.io/quartz//Datasets-overview.png width=auto alt="Table 1: Overview of the datasets by Davidson et al., Founta et al., Waseem and Hovy, and Zampieri et al."></p><ul><li>ì „ì²´ ë°ì´í„°ì…‹ì˜ ê°œìš”ëŠ” ìœ„ ê·¸ë¦¼ê³¼ ê°™ë‹¤.</li></ul><a href=#cross-dataset-training-and-testing><h2 id=cross-dataset-training-and-testing><span class=hanchor arialabel=Anchor># </span>Cross-Dataset Training and Testing</h2></a><p><img src=https://hayul7805.github.io/quartz//Cross-dataset-test-results.png width=auto alt="Table 4: Cross-dataset test results (accuracy and macro-F1)"></p><blockquote><p>Considerable performance drops can be observed when going from a large training dataset to a small test set (i.e., Founta et al.â€™s results when tested on the Waseem and Hovy dataset) and vice versa. This is in line with a similar conclusion by Karan and Å najder(2018).</p></blockquote><ul><li>í° ë°ì´í„°ì…‹ë¶€í„° ì‘ì€ ë°ì´í„°ì…‹ìœ¼ë¡œ ê°ˆ ë•Œ í¼í¬ë¨¼ìŠ¤ í•˜ë½ì´ ë³´ì¸ë‹¤.</li></ul><blockquote><p>The most interesting observation is that <strong>datasets with larger percentages of positive samples tend to</strong> <strong>generalise better than datasets with fewer positive samples</strong>, in particular when <strong>tested against dissimilar datasets</strong>. For example, we see that the models trained on the Davidson et al. dataset, which contains a majority of offensive tags, perform well when tested on the Founta et al. dataset, which contains a majority of non-offensive tags.</p></blockquote><ul><li>ê°€ì¥ í¥ë¯¸ë¡œìš´ ê´€ì°°ì€ ì–‘ì„± ìƒ˜í”Œì˜ ë¹„ìœ¨ì´ í° ë°ì´í„° ì„¸íŠ¸ê°€ íŠ¹íˆ ë‹¤ë¥¸ ë°ì´í„° ì„¸íŠ¸ì— ëŒ€í•´ í…ŒìŠ¤íŠ¸í•  ë•Œ ì–‘ì„± ìƒ˜í”Œì´ ì ì€ ë°ì´í„° ì„¸íŠ¸ë³´ë‹¤ ë” ì˜ ì¼ë°˜í™”ë˜ëŠ” ê²½í–¥ì´ ìˆë‹¤ëŠ” ê²ƒì´ë‹¤. ì˜ˆë¥¼ ë“¤ì–´, ëŒ€ë‹¤ìˆ˜ì˜ ê³µê²© íƒœê·¸ë¥¼ í¬í•¨í•˜ëŠ” Davidson ë“± ë°ì´í„° ì„¸íŠ¸ì— ëŒ€í•´ í›ˆë ¨ëœ ëª¨ë¸ì€ ëŒ€ë‹¤ìˆ˜ì˜ ë¹„ê³µê²© íƒœê·¸ë¥¼ í¬í•¨í•˜ëŠ” Founta ë“± ë°ì´í„° ì„¸íŠ¸ì—ì„œ í…ŒìŠ¤íŠ¸ë  ë•Œ ì„±ëŠ¥ì´ ìš°ìˆ˜í•˜ë‹¤ëŠ” ê²ƒì„ ì•Œ ìˆ˜ ìˆë‹¤.</li><li>ë‚´ ì—°êµ¬ë„ ì´ëŸ° ê²ƒì´ ìˆë‚˜ í™•ì¸í•´ë³´ì.</li></ul><a href=#discussion-and-conclusion><h2 id=discussion-and-conclusion><span class=hanchor arialabel=Anchor># </span>Discussion and Conclusion</h2></a><blockquote><p>Second, experiments showing that datasets with larger percentages of positive samples generalise better than datasets with fewer positive samples when tested against a dissimilar dataset (at least within the same platform, e.g., Twitter), which indicates that a more balanced dataset is healthier for generalisation.</p></blockquote><blockquote><p><strong>An overall conclusion is that the data is more important than the model when tackling Abusive Language Detection.</strong></p></blockquote><ul><li>ë°ì´í„°, ë°ì´í„°! ê²°êµ­ì€ ë°ì´í„°ì˜ ì¤‘ìš”ì„±ì„ ë§í•˜ë©° ì´ ë…¼ë¬¸ì€ ëì„ ë‚¸ë‹¤.</li></ul></article><hr><div class=page-end id=footer><div class=backlinks-container><h3>Backlinks</h3><ul class=backlinks><li><a href=/quartz/notes/Towards-generalisable-hate-speech-detection/ data-ctx="Studying Generalisability Across Abusive Language Detection Datasets" data-src=/notes/Towards-generalisable-hate-speech-detection class=internal-link>Towards generalisable hate speech detection</a></li><li><a href=/quartz/notes/paper-review/ data-ctx="ğŸ“„ Studying Generalisability Across Abusive Language Detection Datasets" data-src=/notes/paper-review class=internal-link>ğŸ“‘ Paper Review</a></li></ul></div><div><script src=https://cdn.jsdelivr.net/npm/d3@6.7.0/dist/d3.min.js integrity="sha256-+7jaYCp29O1JusNWHaYtgUn6EhuP0VaFuswhNV06MyI=" crossorigin=anonymous></script><h3>Interactive Graph</h3><div id=graph-container></div><style>:root{--g-node:var(--secondary);--g-node-active:var(--primary);--g-node-inactive:var(--visited);--g-link:var(--outlinegray);--g-link-active:#5a7282}</style><script src=https://hayul7805.github.io/quartz/js/graph.abd4bc2af3869a96524d7d23b76152c7.js></script></div></div><div id=contact_buttons><footer><p>Made by Hayul Park using <a href=https://github.com/jackyzha0/quartz>Quartz</a>, Â© 2022</p><ul><li><a href=https://hayul7805.github.io/quartz/>Home</a></li><li><a href=https://www.linkedin.com/in/hayulpark>LinkedIn</a></li><li><a href=https://github.com/hayul7805>Github</a></li></ul></footer></div></div></body></html>