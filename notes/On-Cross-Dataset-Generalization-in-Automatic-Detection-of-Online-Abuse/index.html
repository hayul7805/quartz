<!doctype html><html lang=en><head><meta charset=utf-8><meta name=description content="[!info] Reference
Nejadgholi, I., & Kiritchenko, S. (2020). On cross-dataset generalization in automatic detection of online abuse. arXiv preprint arXiv:2010."><title>On Cross-Dataset Generalization in Automatic Detection of Online Abuse</title><meta name=viewport content="width=device-width,initial-scale=1"><link rel="shortcut icon" type=image/png href=https://hayul7805.github.io/quartz//icon.png><link href=https://hayul7805.github.io/quartz/styles.7153093e4d1bbb584a28469cadfa3f88.min.css rel=stylesheet><link href=https://hayul7805.github.io/quartz/styles/_light_syntax.86a48a52faebeaaf42158b72922b1c90.min.css rel=stylesheet id=theme-link><script src=https://hayul7805.github.io/quartz/js/darkmode.f77f63bb01d142b61d2c12fbb4418858.min.js></script>
<script src=https://hayul7805.github.io/quartz/js/util.9825137f5e7825e8553c68ce39ac9e44.min.js></script>
<link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.css integrity=sha384-R4558gYOUz8mP9YWpZJjofhk+zx0AS11p36HnD2ZKj/6JR5z27gSSULCNHIRReVs crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.js integrity=sha384-z1fJDqw8ZApjGO3/unPWUPsIymfsJmyrDVWC8Tv/a1HeOtGmkwNd/7xUS0Xcnvsx crossorigin=anonymous></script>
<script defer src=https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/contrib/auto-render.min.js integrity=sha384-+XBljXPPiv+OzfbB3cVmLHf4hdUFHlWNZN5spNQ7rmHTXpd7WvJum6fIACpNNfIR crossorigin=anonymous></script>
<script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.2/dist/contrib/copy-tex.min.js integrity=sha384-ww/583aHhxWkz5DEVn6OKtNiIaLi2iBRNZXfJRiY1Ai7tnJ9UXpEsyvOITVpTl4A crossorigin=anonymous></script>
<script src=https://unpkg.com/@floating-ui/core@0.7.3></script>
<script src=https://unpkg.com/@floating-ui/dom@0.5.4></script>
<script src=https://hayul7805.github.io/quartz/js/popover.53ad9a087e3feeaaa12b63bfd02d923b.min.js></script>
<script src=https://hayul7805.github.io/quartz/js/code-title.b35124ad8db0ba37162b886afb711cbc.min.js></script>
<script src=https://hayul7805.github.io/quartz/js/clipboard.c20857734e53a3fb733b7443879efa61.min.js></script>
<script src=https://hayul7805.github.io/quartz/js/callouts.7723cac461d613d118ee8bb8216b9838.min.js></script>
<script>const BASE_URL="https://hayul7805.github.io/quartz/",fetchData=Promise.all([fetch("https://hayul7805.github.io/quartz/indices/linkIndex.6013cb2a9851abec94b3760964de3068.min.json").then(e=>e.json()).then(e=>({index:e.index,links:e.links})),fetch("https://hayul7805.github.io/quartz/indices/contentIndex.fa3bbfd3d66e512a476c86217bae0b9f.min.json").then(e=>e.json())]).then(([{index:e,links:t},n])=>({index:e,links:t,content:n})),render=()=>{const e=new URL(BASE_URL),t=e.pathname,n=window.location.pathname,s=t==n;addCopyButtons(),addTitleToCodeBlocks(),addCollapsibleCallouts(),initPopover("https://hayul7805.github.io/quartz",!0,!0);const o=document.getElementById("footer");if(o){const e=document.getElementById("graph-container");if(!e)return requestAnimationFrame(render);e.textContent="";const t=s&&!1;drawGraph("https://hayul7805.github.io/quartz",t,[{"/moc":"#4388cc"}],t?{centerForce:1,depth:-1,enableDrag:!0,enableLegend:!1,enableZoom:!0,fontSize:.5,linkDistance:1,opacityScale:3,repelForce:1,scale:1.4}:{centerForce:1,depth:1,enableDrag:!0,enableLegend:!1,enableZoom:!0,fontSize:.6,linkDistance:1,opacityScale:3,repelForce:2,scale:1.2})}},init=(e=document)=>{addCopyButtons(),addTitleToCodeBlocks(),renderMathInElement(e.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1}],macros:{'’':"'"},throwOnError:!1})}</script><script type=module>
    import { attachSPARouting } from "https:\/\/hayul7805.github.io\/quartz\/js\/router.9d4974281069e9ebb189f642ae1e3ca2.min.js"
    attachSPARouting(init, render)
  </script></head><body><div id=search-container><div id=search-space><input autocomplete=off id=search-bar name=search type=text aria-label=Search placeholder="Search for something..."><div id=results-container></div></div></div><script src=https://cdn.jsdelivr.net/npm/flexsearch@0.7.21/dist/flexsearch.bundle.js integrity="sha256-i3A0NZGkhsKjVMzFxv3ksk0DZh3aXqu0l49Bbh0MdjE=" crossorigin=anonymous defer></script>
<script defer src=https://hayul7805.github.io/quartz/js/full-text-search.24827f874defbbc6d529926cbfcfb493.min.js></script><div class=singlePage><header><h1 id=page-title><a href=https://hayul7805.github.io/quartz/>🌱 Hayul's digital garden</a></h1><div class=spacer></div><div id=search-icon><p>Search</p><svg tabindex="0" aria-labelledby="title desc" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 19.9 19.7"><title id="title">Search Icon</title><desc id="desc">Icon to open search</desc><g class="search-path" fill="none"><path stroke-linecap="square" d="M18.5 18.3l-5.4-5.4"/><circle cx="8" cy="8" r="7"/></g></svg></div><div class=darkmode><input class=toggle id=darkmode-toggle type=checkbox tabindex=-1>
<label id=toggle-label-light for=darkmode-toggle tabindex=-1><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" id="dayIcon" viewBox="0 0 35 35" style="enable-background:new 0 0 35 35"><title>Light Mode</title><path d="M6 17.5C6 16.672 5.328 16 4.5 16h-3C.672 16 0 16.672.0 17.5S.672 19 1.5 19h3C5.328 19 6 18.328 6 17.5zM7.5 26c-.414.0-.789.168-1.061.439l-2 2C4.168 28.711 4 29.086 4 29.5 4 30.328 4.671 31 5.5 31c.414.0.789-.168 1.06-.44l2-2C8.832 28.289 9 27.914 9 27.5 9 26.672 8.329 26 7.5 26zm10-20C18.329 6 19 5.328 19 4.5v-3C19 .672 18.329.0 17.5.0S16 .672 16 1.5v3C16 5.328 16.671 6 17.5 6zm10 3c.414.0.789-.168 1.06-.439l2-2C30.832 6.289 31 5.914 31 5.5 31 4.672 30.329 4 29.5 4c-.414.0-.789.168-1.061.44l-2 2C26.168 6.711 26 7.086 26 7.5 26 8.328 26.671 9 27.5 9zM6.439 8.561C6.711 8.832 7.086 9 7.5 9 8.328 9 9 8.328 9 7.5c0-.414-.168-.789-.439-1.061l-2-2C6.289 4.168 5.914 4 5.5 4 4.672 4 4 4.672 4 5.5c0 .414.168.789.439 1.06l2 2.001zM33.5 16h-3c-.828.0-1.5.672-1.5 1.5s.672 1.5 1.5 1.5h3c.828.0 1.5-.672 1.5-1.5S34.328 16 33.5 16zM28.561 26.439C28.289 26.168 27.914 26 27.5 26c-.828.0-1.5.672-1.5 1.5.0.414.168.789.439 1.06l2 2C28.711 30.832 29.086 31 29.5 31c.828.0 1.5-.672 1.5-1.5.0-.414-.168-.789-.439-1.061l-2-2zM17.5 29c-.829.0-1.5.672-1.5 1.5v3c0 .828.671 1.5 1.5 1.5s1.5-.672 1.5-1.5v-3C19 29.672 18.329 29 17.5 29zm0-22C11.71 7 7 11.71 7 17.5S11.71 28 17.5 28 28 23.29 28 17.5 23.29 7 17.5 7zm0 18c-4.136.0-7.5-3.364-7.5-7.5s3.364-7.5 7.5-7.5 7.5 3.364 7.5 7.5S21.636 25 17.5 25z"/></svg></label><label id=toggle-label-dark for=darkmode-toggle tabindex=-1><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" id="nightIcon" viewBox="0 0 100 100" style="enable-background='new 0 0 100 100'"><title>Dark Mode</title><path d="M96.76 66.458c-.853-.852-2.15-1.064-3.23-.534-6.063 2.991-12.858 4.571-19.655 4.571C62.022 70.495 50.88 65.88 42.5 57.5 29.043 44.043 25.658 23.536 34.076 6.47c.532-1.08.318-2.379-.534-3.23-.851-.852-2.15-1.064-3.23-.534-4.918 2.427-9.375 5.619-13.246 9.491-9.447 9.447-14.65 22.008-14.65 35.369.0 13.36 5.203 25.921 14.65 35.368s22.008 14.65 35.368 14.65c13.361.0 25.921-5.203 35.369-14.65 3.872-3.871 7.064-8.328 9.491-13.246C97.826 68.608 97.611 67.309 96.76 66.458z"/></svg></label></div></header><article><h1>On Cross-Dataset Generalization in Automatic Detection of Online Abuse</h1><p class=meta>Last updated
Nov 5, 2022</p><ul class=tags><li><a href=https://hayul7805.github.io/quartz/tags/generalization/>Generalization</a></li></ul><aside class=mainTOC><details><summary>Table of Contents</summary><nav id=TableOfContents><ol><li><a href=#research-questions>Research Questions</a></li><li><a href=#실험-방법>실험 방법</a></li><li><a href=#실험-결과>실험 결과</a><ol><li><a href=#formulation에-대한-논의>Formulation에 대한 논의</a></li></ol></li><li><a href=#impact-of-data-size-on-generalizability>Impact of Data Size on Generalizability</a></li><li><a href=#discussion>Discussion</a></li></ol></nav></details></aside><blockquote class=info-callout><p>Reference</p><p>Nejadgholi, I., & Kiritchenko, S. (2020). On cross-dataset generalization in automatic detection of online abuse. <em>arXiv preprint arXiv:2010.07414</em>.</p></blockquote><hr><a href=#research-questions><h2 id=research-questions><span class=hanchor arialabel=Anchor># </span>Research Questions</h2></a><blockquote><p>Test and training sets were created for each dataset by performing a stratified split of 20% vs 80%, with the larger part used for training the models. The training sets were further subdivided, keeping 1/8 shares of them as separate validation sets during development and fine-tuning of the hyper-parameters.</p></blockquote><ul><li>Fine-tuning에서의 일반적인 방법을 말하고 있다. 전체 데이터를 label 분포를 유지한 채로 <code>train</code>, <code>test</code> 으로 나누고, 이후 <code>train</code>에서 <code>validation</code>을 다시 나눈다. 특히 <code>test</code> 데이터셋은 훈련에 쓰이지 않는데, 이후 학습한 모델의 일반화 성능을 평가할 때 사용한다. 그래서 <code>test</code> 데이터셋에서 성능이 잘 나온다면, 해당 모델이 다른 데이터셋에서도 성능이 잘 나올 것이라는 가설을 세울 수 있다.</li><li>그러나 본 논문은 이 가설에 의문을 제기한다.</li></ul><blockquote><p>(&mldr;) the aim here, in contrast, was to see <strong>how well the best models (that may have learnt some dataset-specific biases) performed on other datasets.</strong> <strong>This was done to investigate how well state-of-the-art systems perform in a real-life scenario</strong>, i.e., when exposed to data from other domains, with the hypothesis that a model trained on one dataset that exhibits comparatively reasonable results on other datasets can be expected to generalise well.</p></blockquote><ul><li>이 논문의 목적은 그렇게 한 데이터셋을 잘 학습한(아마도 그 데이터셋에 내재한 편향도 잘 학습한) 모델이 다른 데이터셋에 얼마나 성능이 좋은지 보는 것이다. 이건 실제 세계에서의 상황과 유사한데, 모델은 결국 다른 도메인에서 생성된 데이터에 노출될 수 밖에 없기 때문이다.</li><li>이를 통해 <em>&lsquo;한 데이터셋을 잘 학습하여 좋은 성능을 내는 모델이라면, 다른 데이터셋에도 잘 일반화를 할 수 있을 것</em>&lsquo;이라는 가설을 실제로 확인해보는 것이다.</li></ul><a href=#실험-방법><h2 id=실험-방법><span class=hanchor arialabel=Anchor># </span>실험 방법</h2></a><blockquote><p>To explore how well the Toxic class from the Wiki-dataset generalizes to other types of offensive behaviour, <strong>we train a binary classifier (Toxic vs. Normal) on the Wiki-dataset (combining the train, development and test sets) and test it on the Out-of-Domain Test set.</strong> This classifier is expected to predict a positive (Toxic) label for the instances of classes Founta-Abusive, Founta-Hateful, Waseem-Sexism and Waseem-Racism, and a negative (Normal) label for the tweets in the Founta-Normal class. We fine-tune a BERT-based classifier (Devlin et al., 2019) with a linear prediction layer, the batch size of 16 and the learning rate of 2 × 10−5 for 2 epochs.</p></blockquote><ul><li>저자들은 Wiki-dataset으로 훈련한 모델이 다른 데이터셋에 얼마나 잘 일반화하는가를 보기 위해, binary classifier를 wiki-Dataset으로 훈련시키고 <em>&lsquo;도메인 외 테스트셋(the Out-of-Domain Test set)&rsquo;</em> 에 이를 테스트 했다. 모델은 BERT를 사용했다.</li></ul><a href=#실험-결과><h2 id=실험-결과><span class=hanchor arialabel=Anchor># </span>실험 결과</h2></a><p><img src=https://hayul7805.github.io/quartz//notes/images/table3.png width=auto alt="Table 3"></p><blockquote><p>Results: The overall performance of the classifier on the Out-of-Domain test set is quite high: weighted macro-averaged F1 = 0.90.</p></blockquote><ul><li>저자들의 예상과 달리 전체적인 Out-of-Domain test 성능은 높은 편이었다. 그러나 Waseem 데이터셋의 Sexist, Racist class를 분류하는 데에는 Wiki-Dataset의 Toxic class로 훈련된 모델이 적합하지 않다는 사실을 확인했다.</li></ul><a href=#formulation에-대한-논의><h3 id=formulation에-대한-논의><span class=hanchor arialabel=Anchor># </span>Formulation에 대한 논의</h3></a><p>#key-observation</p><blockquote><p>The impact of task formulation: From task formulations described in Section 3, observe that the Wiki-dataset defines the class Toxic in a general way. The class Founta-Abusive is also a general formulation of offensive behaviour. The similarity of these two definitions is reflected clearly in our results.</p></blockquote><ul><li>흥미로운 분석은 Formulation에 대한 것이다. 먼저 Wiki dataset의 Tosic class에 대한 정의는 다음과 같다 : &lsquo;The class Toxic comprises rude, hateful, aggressive, disrespectful or unreasonable comments that are likely to make a person leave a conversation&rsquo;.</li><li>그런데 이것이, Waseem 데이터셋의 Sexist, Racist class를 분류하기에는 다소 일반적인 정의라는 것이다.</li></ul><a href=#impact-of-data-size-on-generalizability><h2 id=impact-of-data-size-on-generalizability><span class=hanchor arialabel=Anchor># </span>Impact of Data Size on Generalizability</h2></a><p>#data-size</p><blockquote><p>Observe that the average accuracies remain unchanged when the dataset’s size triples at the same class balance ratio. This finding contrasts with the general assumption that more training data results in a higher classification performance.</p></blockquote><ul><li>다음으로 저자는 또 흥미로운 포인트를 하나 더 확인했다.</li><li>만약 class의 비율이 변하지 않는다면 데이터의 크기가 커지더라도 정확도(<code>accuracy</code>)는 변하지 않는다는 것이다. 이는 더 많은 훈련데이터가 항상 높은 분류 성능을 낸다는 general assumption과 반대되는 결과이다.</li></ul><a href=#discussion><h2 id=discussion><span class=hanchor arialabel=Anchor># </span>Discussion</h2></a><blockquote><p>In the task of online abuse detection, both False Positive and False Negative errors can lead to significant harm as one threatens the freedom of speech and ruins people’s reputations, and the other ignores hurtful behaviour.</p></blockquote><ul><li>False Positive와 False Negative는 표현의 자유를 위협할 수 있다.</li></ul><blockquote><p>We suggest evaluating each class (both positive and negative) separately taking into account the potential costs of different types of errors.</p></blockquote><ul><li>그리고 저자들은 각 class를 따로 평가하는 것을 제안했다.</li></ul></article><hr><div class=page-end id=footer><div class=backlinks-container><h3>Backlinks</h3><ul class=backlinks><li><a href=/quartz/notes/Studying-Generalisability-Across-Abusive-Language-Detection-Datasets/ data-ctx="On Cross-Dataset Generalization in Automatic Detection of Online Abuse" data-src=/notes/Studying-Generalisability-Across-Abusive-Language-Detection-Datasets class=internal-link>Studying Generalisability Across Abusive Language Detection Datasets</a></li><li><a href=/quartz/notes/Towards-generalisable-hate-speech-detection/ data-ctx="On Cross-Dataset Generalization in Automatic Detection of Online Abuse" data-src=/notes/Towards-generalisable-hate-speech-detection class=internal-link>Towards generalisable hate speech detection</a></li><li><a href=/quartz/notes/paper-review/ data-ctx="📄 On Cross-Dataset Generalization in Automatic Detection of Online Abuse" data-src=/notes/paper-review class=internal-link>📑 Paper Review</a></li></ul></div><div><script src=https://cdn.jsdelivr.net/npm/d3@6.7.0/dist/d3.min.js integrity="sha256-+7jaYCp29O1JusNWHaYtgUn6EhuP0VaFuswhNV06MyI=" crossorigin=anonymous></script><h3>Interactive Graph</h3><div id=graph-container></div><style>:root{--g-node:var(--secondary);--g-node-active:var(--primary);--g-node-inactive:var(--visited);--g-link:var(--outlinegray);--g-link-active:#5a7282}</style><script src=https://hayul7805.github.io/quartz/js/graph.abd4bc2af3869a96524d7d23b76152c7.js></script></div></div><div id=contact_buttons><footer><p>Made by Hayul Park using <a href=https://github.com/jackyzha0/quartz>Quartz</a>, © 2022</p><ul><li><a href=https://hayul7805.github.io/quartz/>Home</a></li><li><a href=https://www.linkedin.com/in/hayulpark>LinkedIn</a></li><li><a href=https://github.com/hayul7805>Github</a></li></ul></footer></div></div></body></html>